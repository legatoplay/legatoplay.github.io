{"meta":{"title":"Gary's Blog","subtitle":null,"description":"主攻JAVA。","author":"Gary","url":"https://legatoplay.github.io","root":"/"},"pages":[{"title":"categories","date":"2018-08-06T03:45:31.000Z","updated":"2019-04-16T06:33:18.601Z","comments":true,"path":"categories/index.html","permalink":"https://legatoplay.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-08-06T03:44:56.000Z","updated":"2019-04-16T06:33:18.604Z","comments":true,"path":"tags/index.html","permalink":"https://legatoplay.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"JVM（二）：JAVA堆","slug":"JVM（二）：JAVA堆","date":"2019-05-10T07:13:30.000Z","updated":"2019-05-10T07:50:44.267Z","comments":true,"path":"2019/05/10/JVM（二）：JAVA堆/","link":"","permalink":"https://legatoplay.github.io/2019/05/10/JVM（二）：JAVA堆/","excerpt":"摘自：https://blog.csdn.net/en_joker/article/details/79737533摘自：https://www.cnblogs.com/cjsblog/p/9850300.html摘自：https://lhc1986.iteye.com/blog/1421832 堆内存划分&emsp;&emsp;在JDK1.7以及其前期的JDK版本中，堆内存通常被分为三块区域：Young Generation、Old Generation、Permanent Generation for VM Matedata &emsp;&emsp;在JDK1.8中把存放元数据中的永久内存从堆内存中移到了本地内存中，JDK1.8中JVM堆内存结构就变成了如下：","text":"摘自：https://blog.csdn.net/en_joker/article/details/79737533摘自：https://www.cnblogs.com/cjsblog/p/9850300.html摘自：https://lhc1986.iteye.com/blog/1421832 堆内存划分&emsp;&emsp;在JDK1.7以及其前期的JDK版本中，堆内存通常被分为三块区域：Young Generation、Old Generation、Permanent Generation for VM Matedata &emsp;&emsp;在JDK1.8中把存放元数据中的永久内存从堆内存中移到了本地内存中，JDK1.8中JVM堆内存结构就变成了如下： 分代收集算法&emsp;&emsp;当前商业虚拟机的垃圾收集都采用“分代收集”（Generational Collection）算法，这种算法并没有什么新的思想，只是根据对象存活周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适合的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成。而老年代中因为对象存活率高、没有额外空间对他进行分配担保，就必须使用“标记-清理”或者“标记-整理”算法来进行回收。 一个人（对象）出来（new 出来）后会在Eden Space（伊甸园）无忧无虑的生活，直到GC（YoungGC）到来打破了他们平静的生活。GC（YoungGC）会逐一问清楚每个对象的情况，有没有钱（此对象的引用）啊，因为GC想赚钱呀，有钱的才可以敲诈嘛。然后富人就会进入Survivor Space（幸存者区），穷人的就直接kill掉。 &emsp;&emsp;(1) 把还存活的对象复制到From区 &emsp;&emsp;(2) 当Eden区再次被用完，就再触发一次YoungGC，会将Eden区与From区还在被使用的对象复制到To区 &emsp;&emsp;(3) 再触发YoungGC，Eden区与To区中的还在被使用的对象复制到From区 并不是进入Survivor Space（幸存者区）后就保证人身是安全的，但至少可以活段时间。GC（YoungGC）会定期（可以自定义）会对这些人进行敲诈，亿万富翁每次都给钱，GC（YoungGC）很满意，就让其进入了Genured Gen(养老区)。万元户经不住几次敲诈就没钱了，GC（YoungGC）看没有啥价值啦，就直接kill掉了。 进入到养老区的人基本就可以保证人身安全啦，但是亿万富豪有的也会挥霍成穷光蛋，只要钱没了（空间耗尽），GC（Full GC）还是kill掉。","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://legatoplay.github.io/categories/JAVA/"},{"name":"JVM","slug":"JAVA/JVM","permalink":"https://legatoplay.github.io/categories/JAVA/JVM/"}],"tags":[{"name":"基础知识","slug":"基础知识","permalink":"https://legatoplay.github.io/tags/基础知识/"},{"name":"JAVA","slug":"JAVA","permalink":"https://legatoplay.github.io/tags/JAVA/"}]},{"title":"JVM（一）：JVM内存模型","slug":"JVM（一）-JVM内存模型","date":"2019-05-10T03:24:12.000Z","updated":"2019-05-10T07:26:12.181Z","comments":true,"path":"2019/05/10/JVM（一）-JVM内存模型/","link":"","permalink":"https://legatoplay.github.io/2019/05/10/JVM（一）-JVM内存模型/","excerpt":"摘自：https://www.cnblogs.com/cjsblog/p/9850300.html摘自：https://blog.csdn.net/itermeng/article/details/74977888摘自：(https://blog.csdn.net/laomo_bible/article/details/83067810 运行时区域内存&emsp;&emsp;Java虚拟机在执行Java程序时会将其管理的区域划分为不同的数据区域，不同区域之间拥有各自用途、创建和销毁的时间，有的区域随着虚拟机进程的启动而存在，而有的区域则依赖用户线程的生命周期。 table th:first-of-type { width: 12%; } table th { font-weight: bold; text-align: center !important; background: rgba(158,188,226,0.2); white-space: nowrap; } 名称 特征 作用 配置参数 异常 程序计数器 占用内存小，线程私有，生命周期与线程相同 大致为字节码行号指示器 无 无 虚拟机栈 线程私有，生命周期与线程相同，使用连续的内存空间 Java 方法执行的内存模型，存储局部变量表、操作栈、动态链接、方法出口等信息 -Xss StackOverflowError OutOfMemoryError java堆 线程共享，生命周期与虚拟机相同，可以不使用连续的内存地址 保存对象实例，所有对象实例（包括数组）都要在堆上分配 -Xms-Xsx-Xmn OutOfMemoryError 方法区 线程共享，生命周期与虚拟机相同，可以不使用连续的内存地址 存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据 OutOfMemoryError 运行时常量池 方法区的一部分，具有动态性 存放字面量及符号引用 &nbsp; &nbsp;","text":"摘自：https://www.cnblogs.com/cjsblog/p/9850300.html摘自：https://blog.csdn.net/itermeng/article/details/74977888摘自：(https://blog.csdn.net/laomo_bible/article/details/83067810 运行时区域内存&emsp;&emsp;Java虚拟机在执行Java程序时会将其管理的区域划分为不同的数据区域，不同区域之间拥有各自用途、创建和销毁的时间，有的区域随着虚拟机进程的启动而存在，而有的区域则依赖用户线程的生命周期。 table th:first-of-type { width: 12%; } table th { font-weight: bold; text-align: center !important; background: rgba(158,188,226,0.2); white-space: nowrap; } 名称 特征 作用 配置参数 异常 程序计数器 占用内存小，线程私有，生命周期与线程相同 大致为字节码行号指示器 无 无 虚拟机栈 线程私有，生命周期与线程相同，使用连续的内存空间 Java 方法执行的内存模型，存储局部变量表、操作栈、动态链接、方法出口等信息 -Xss StackOverflowError OutOfMemoryError java堆 线程共享，生命周期与虚拟机相同，可以不使用连续的内存地址 保存对象实例，所有对象实例（包括数组）都要在堆上分配 -Xms-Xsx-Xmn OutOfMemoryError 方法区 线程共享，生命周期与虚拟机相同，可以不使用连续的内存地址 存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据 OutOfMemoryError 运行时常量池 方法区的一部分，具有动态性 存放字面量及符号引用 &nbsp; &nbsp; 1. 程序计数器（1）含义作用&emsp;&emsp;程序计数器（Program Counter Register）是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。在虚拟机概念模型中，字节码解释器工作时就是通过改变计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖计数器。 （2）计数器与多线程&emsp;&emsp;由于JVM的多线程时通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）都只会执行一条线程中的指令。所以，为了线程切换后能恢复到正确的执行位置，每条线程需要一个独立的程序计数器，各线程之间计数器互不影响、独立存储，相当于是一块“线程私有”的内存。 （3）虚拟机规范记录（有关异常）&emsp;&emsp;若线程正在执行的是一个Java方法，这个计数器记录的时正在执行的虚拟机字节码指令的地址；若执行的是Native方法，则计数器为空（Undefined）。注意：此内存区域是唯一一个在Java虚拟机规范中没有规定任何 OutOfMemoryError情况的区域。 2 . Java虚拟机栈（1）含义作用&emsp;&emsp;同程序计数器相同，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成的过程，会对应一个栈帧在虚拟机栈中入栈到出栈的过程。 （2）Java内存区分误区&emsp;&emsp;大多数人以为Java内存区分为堆内存（Heap）和栈内存（Stack），这是一种误区，Java内存区域的划分远比这种粗糙的分法更加复杂。这种划分方式广泛流传是由于大多数开发者关注与对象内存分配关系最密切的内存区域就是这两块，有关“堆”的知识后续载提，这里的“栈”指的就是虚拟机栈，或者说是虚拟机栈中的变量表部分。 （3）虚拟机栈中的局部变量表&emsp;&emsp;局部变量表中存放了编译期可知的 八大数据类型（boolean、byte、char、short、int、float、long、double）。 对象引用（reference类型，它不等于对象本身，可能是一个指向对象起始地址的指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置） returnAddress类型（指向了一条字节码指令的地址） &emsp;&emsp;其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余数据类型只占用1个。局部变量表所需的内存控件在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。 （4）虚拟机规范记录（有关异常）&emsp;&emsp;在Java虚拟机规范中，对这个区域规定了两种异常状况： 若线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常。 若虚拟机可以动态扩展（当前大部分Java虚拟机都可动态扩展，只不过Java虚拟机规范也允许固定长度的虚拟机栈），当扩展时无法申请到足够的内存，就会抛出OutOfMemoryError异常。 3 . 本地方法栈（1）含义作用&emsp;&emsp;本地方法栈（Native Method Stack）与虚拟机栈所发挥的作用类似，它们之间的区别是：虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则为虚拟机使用到的Native方法服务。 （2）虚拟机规范记录（有关异常）&emsp;&emsp;在虚拟机规范中对本地方法栈中使用的语言、方式和数据结构并无强制规定，因此具体的虚拟机可实现它。甚至有的虚拟机（Sun HotSpot虚拟机）直接把本地方法栈和虚拟机栈合二为一。 &emsp;&emsp;与虚拟机一样，本地方法栈会抛出StackOverflowError和OutOfMemoryError异常。 4 . Java堆（1）含义作用&emsp;&emsp;对于大多数应用而言，Java堆（Heap）是Java虚拟机所管理的内存中最大的一块，它是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域唯一的目的是存放对象实例，几乎所有的对象实例都在这里分配内存。Java虚拟机规范中描述道：所有的对象实例以及数组都要在堆上分配，但是随着JIT编译器的发展和逃逸分析技术逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化发生，所有的对象都在堆上分配的定论也并不“绝对”了。 （2）Java堆与垃圾回收器&emsp;&emsp;Java堆是垃圾回收器管理的主要区域，因此被称为“GC堆”（Garbage Collected Heap）。 &emsp;&emsp;从内存回收角度看，由于目前收集器基本采用分代收集算法，所以Java堆可细分为：新生代和老年代。&emsp;&emsp;从内存分配角度来看，线程共享的Java堆中可能划分出多个线程私有的分配缓冲区（TLAB：Thread Local Allocation Buffer）。&emsp;&emsp;不过无论如何划分，都与存放内容无关，无论哪个区域，存放的都是对象实例，进一步划分目的是为了更好地回收内存，或者是更快地分配内存。此节仅对内存区域作用进行学习，Java堆上各个区域分配回收等细节与内存分配策略有关，后续讲解。 （3）虚拟机规范记录（有关异常）&emsp;&emsp;根据Java虚拟机规范的规定，Java堆可以处于物理上不连续的内存中，只要逻辑上是连续的即可，就像磁盘空间。在实现时，可以实现成固定大小或可扩展的，不过当前主流虚拟机是按照可扩展进行实现的（通过-Xmx和 -Xms控制）。 &emsp;&emsp;若堆中没有内存完成实例分配，并且堆也无法扩展时，将会抛出OutOfMemoryError异常。 5 . 方法区（1）含义作用&emsp;&emsp;方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它有一个别名叫做 Non-Heap（非堆），目的是为了和Java堆区分开来。 &emsp;&emsp;从jdk1.7已经开始准备“去永久代”的规划，jdk1.7的HotSpot中，已经把原本放在方法区中的静态变量、字符串常量池等移到堆内存中。 PermGen（永久代）&emsp;&emsp;方法区是JVM的规范，而永久代是方法区的一种实现，并且只有HotSpot才有PermGen space，而对于其他类型的虚拟机并没有PermGen space。 &emsp;&emsp;在JDK1.8中，HotSpot已经没有PermGen space这个区间了，取而代之是Metaspace（元空间） Metaspace（元空间）&emsp;&emsp;在JDK1.8中，永久代已经不存在，存储的类信息、编译后的代码数据等已经移动到了MetaSpace（元空间）中，元空间并没有处于堆内存上，而是直接占用的本地内存（NativeMemory）。 &emsp;&emsp;元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。 &emsp;&emsp;元空间的大小仅受本地内存限制，可以通过以下参数来指定元空间大小： -XX:MetaspaceSize，初始空间大小，达到该值就会触发垃圾收集进行类型卸载，同时GC会对该值进行调整：如果释放了大量的空间，就适当降低该值；如果释放了很少的空间，那么在不超过MaxMetaspaceSize时，适当提高该值 -XX:MaxMetaspaceSize，最大空间，默认是没有限制的 -XX:MinMetaspaceFreeRatio，在GC之后，最小的Metaspace剩余空间容量的百分比，减少为分配空间所导致的垃圾收集 -XX:MaxMetaspaceFreeRatio，在GC之后，最大的Metaspace剩余空间容量的百分比，减少为释放空间所导致的垃圾收集 （2）虚拟机规范记录（有关异常）&emsp;&emsp;Java虚拟机规范对方法区的限制非常宽松，除了和Java堆一样不需要连续的内存和可以选择固定大小或可扩展外，还可以选择不实现垃圾收集。相对而言，垃圾收集行为在这个区域比较少见。此区域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说，回收效果难以令人满意，尤其是类型的卸载，条件相对苛刻，但是这部分区域回收是有必要的。 &emsp;&emsp;根据Java虚拟机规范的规定，当方法无法满足内存需求时，将会抛出OutOfMemoryError异常。 6 . 运行时常量池（1）含义作用&emsp;&emsp;运行时常量池（Runtime Constant Pool）是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池（Constant Pool Table），用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池存放。 （2）运行时常量池和Class文件&emsp;&emsp;Java虚拟机对Class文件每一部分（自然包括常量池）的格式有严格规定，每一个字节用于存储那种数据都必须符合规范上的要求才会被虚拟机认可、装载和执行。但对于运行时常量池，Java虚拟机规范没有做任何有关细节的要求，不同的提供商实现的虚拟机可以按照自己的需求来实现此内存区域。不过一般而言，除了保存Class文件中的描述符号引用外，还会把翻译出的直接引用也存储在运行时常量池中。 &emsp;&emsp;运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性，Java语言并不要求常量一定只有编译器才能产生，也就是并非置入Class文件中的常量池的内容才能进入方法区运行时常量池，运行期间也可能将新的常量放入池中，此特性被开发人员利用得比较多的便是String类的intern() 方法。 （3）虚拟机规范记录（有关异常）&emsp;&emsp;运行时常量池是方法区的一部分，自然受到方法区的内存限制，当常量池无法再申请到内存时会抛出OutOfMemoryError异常。 7 . 直接内存（1）含义作用&emsp;&emsp;直接内存（Direct Memory）并不是虚拟机运行时数据的一部分，也不是Java虚拟机规范中定义的内存区域。但这部分内存也被频繁运用，而却可能导致OutOfMemoryError异常出现。 （2）有关异常&emsp;&emsp;本机直接内存的分配不会受到Java堆大小的限制，但是既然是内存，还是会受到本机总内存（包括RAM以及SWAP区或分页文件）大小以及处理器寻址空间的限制。服务器管理员在配置虚拟机参数时，会根据实际内存设置-Xmx等参数信息，但经常忽略直接内存，使得各个内存区域总和大于物理内存限制（包括物理的和操作系统的限制），从而导致动态扩展时出现OutOfMemoryError异常。","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://legatoplay.github.io/categories/JAVA/"},{"name":"JVM","slug":"JAVA/JVM","permalink":"https://legatoplay.github.io/categories/JAVA/JVM/"}],"tags":[{"name":"基础知识","slug":"基础知识","permalink":"https://legatoplay.github.io/tags/基础知识/"},{"name":"JAVA","slug":"JAVA","permalink":"https://legatoplay.github.io/tags/JAVA/"}]},{"title":"前后端分离-JWT","slug":"JWT","date":"2019-04-17T07:26:17.000Z","updated":"2019-05-10T03:05:55.277Z","comments":true,"path":"2019/04/17/JWT/","link":"","permalink":"https://legatoplay.github.io/2019/04/17/JWT/","excerpt":"参考：jwt.io参考：https://blog.csdn.net/bntx2jsqfehy7/article/details/79224042参考：https://blog.csdn.net/kevin_lcq/article/details/74846723参考：https://www.cnblogs.com/eret9616/p/9661314.html Cookie&amp;SessionHTTP的无状态性&emsp;&emsp;HTTP 是无状态协议，它不对之前发送过的请求和响应的状态进行管理。也就是说，无法根据之前的状态进行本次的请求处理。假设要求登录认证的 Web 页面本身无法进行状态的管理（不记录已登录的状态），那么每次跳转新页面不是要再次登录，就是要在每次请求报文中附加参数来管理登录状态。 &emsp;&emsp;不可否认，无状态协议当然也有它的优点。由于不必保存状态，自然可减少服务器的 CPU 及内存资源的消耗。从另一侧面来说，也正是因为 HTTP 协议本身是非常简单的，所以才会被应用在各种场景里。","text":"参考：jwt.io参考：https://blog.csdn.net/bntx2jsqfehy7/article/details/79224042参考：https://blog.csdn.net/kevin_lcq/article/details/74846723参考：https://www.cnblogs.com/eret9616/p/9661314.html Cookie&amp;SessionHTTP的无状态性&emsp;&emsp;HTTP 是无状态协议，它不对之前发送过的请求和响应的状态进行管理。也就是说，无法根据之前的状态进行本次的请求处理。假设要求登录认证的 Web 页面本身无法进行状态的管理（不记录已登录的状态），那么每次跳转新页面不是要再次登录，就是要在每次请求报文中附加参数来管理登录状态。 &emsp;&emsp;不可否认，无状态协议当然也有它的优点。由于不必保存状态，自然可减少服务器的 CPU 及内存资源的消耗。从另一侧面来说，也正是因为 HTTP 协议本身是非常简单的，所以才会被应用在各种场景里。 Cookie技术的引入&emsp;&emsp;如果让服务器管理全部客户端状态则会成为负担，保留无状态协议这个特征的同时又要解决类似的矛盾问题，于是引入了 Cookie 技术。Cookie 技术通过在请求和响应报文中写入Cookie信息来控制客户端的状态。 &emsp;&emsp;Cookie会根据从服务器端发送的响应报文内的一个叫做Set-Cookie 的首部字段信息，通知客户端保存 Cookie。当下次客户端再往该服务器发送请求时，客户端会自动在请求报文中加入Cookie 值后发送出去。 基于Session的登录&emsp;&emsp;目前用户的认证多半是基于表单的认证，基于表单的认证一般会使用 Cookie 来管理Session（Session会话，Session代表着服务器和客户端一次会话的过程，直到Session失效（服务端关闭）或者客户端关闭时结束）。基于表单认证本身是通过服务器端的 Web应用，将客户端发送过来的用户ID和密码与之前登录过的信息做匹配来进行认证的。&emsp;&emsp;但鉴于 HTTP 是无状态协议， 之前已认证成功的用户状态无法通过协议层面保存下来。 即无法实现状态管理， 因此即使当该用户下一次继续访问，也无法区分他与其他的用户。于是我们会使用Cookie 来管理 Session，以弥补 HTTP 协议中不存在的状态管理功能。 同源策略&emsp;&emsp;同源策略（Same origin policy）是一种约定，它是浏览器最核心也最基本的安全功能，如果缺少了同源策略，则浏览器的正常功能可能都会受到影响。可以说 Web 是构建在同源策略基础之上的，浏览器只是针对同源策略的一种实现。 &emsp;&emsp;只有满足以下三种情况浏览器才会认定为同源： 123• 协议相同• 域名相同• 端口相同 同源问题解决 JSOUP 123456789$.ajax(&#123; dataType:'jsonp', data:'id=10', jsonp:'jsonp_callback', url:'http://www.yiwuku.com/getdata', success:function()&#123; //dostuff &#125;, &#125;); CORS CORS需要浏览器和服务器同时支持。（通过@CrossOrigin注解允许跨域，origins设置了允许跨域请求的域，allowCredentials允许设置和接受Cookie。） 集群情况下的问题&emsp;&emsp;Session 是存储在Web服务器（例如：Tomcat）中的，并针对每个客户端（客户），通过SessionID来区别不同用户的。Session是以Cookie技术或URL重写实现，默认以Cookie技术实现，服务端会给这次会话创造一个JSESSIONID的Cookie值。&emsp;&emsp;但是一个显著的问题就是，在集群模式下如果通过Nginx负载均衡的时候，如果有一个用户登录的时候请求被分配到服务器A上，登录成功后设置的Session就会存放在服务器A上了，但是在服务器B上却没有该用户的Session数据，当用户再次发起一个请求的时候，此时请求如果被分配到服务器B上，则就不会查询到该用户的登录状态，就会出现登录失败的情况！&emsp;&emsp;一种可以想到的方式就是将多个Web服务器上存储的Session统一存储到某一存储介质中，保证进集群中的每一台机器都可以看到所有相同Session数据，这里的同步体现在所有的Session存储在同一的存储介质里边。 spring-session 1、使用Redis存储Nginx+Tomcat负载均衡集群的Session 2、使用Spring Session和Redis解决分布式Session跨域共享问题 3、Spring Session解决分布式Session问题的实现原理 JWT(JSON Web Token)&emsp;&emsp;jwt是目前最流行的跨域认证解决方案;原理是json对象+签名。Ebook JWT数据结构 &emsp;&emsp;JWT包含三个由点（.）分隔的部分，它们是： 头部（header） 有效负载（payload） 签名（signature） 12//Header.Payload.SignatureeyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c header&emsp;&emsp;Header 部分是一个 JSON 对象，描述 JWT 的元数据，通常是下面的样子。 123456&#123; \"alg\": \"HS256\",//令牌的类型 \"typ\": \"JWT\"//散列算法&#125; &emsp;&emsp;最后，将上面的 JSON 对象使用 Base64URL 算法转成字符串。 Payload&emsp;&emsp;Payload 部分也是一个 JSON 对象，用来存放实际需要传递的数据。JWT 规定了7个官方字段，供选用。 1234567• iss (issuer)：签发人• exp (expiration time)：过期时间• sub (subject)：主题• aud (audience)：受众• nbf (Not Before)：生效时间• iat (Issued At)：签发时间• jti (JWT ID)：编号 &emsp;&emsp;除了官方字段，还可以在这个部分定义私有字段，下面就是一个例子。 12345&#123; \"sub\": \"1234567890\", \"name\": \"John Doe\", \"admin\": true&#125; &emsp;&emsp;注意，JWT 默认是不加密的，任何人都可以读到，所以不要把秘密信息放在这个部分。这个 JSON 对象也要使用Base64URL 算法转成字符串。 Signature&emsp;&emsp;Signature 部分是对前两部分的签名，防止数据篡改。 &emsp;&emsp;首先，需要指定一个密钥（secret）。这个密钥只有服务器才知道，不能泄露给用户。然后，使用 Header 里面指定的签名算法（默认是 HMAC SHA256），按照下面的公式产生签名。 1234HMACSHA256( base64UrlEncode(header) + \".\" + base64UrlEncode(payload), secret) &emsp;&emsp;算出签名以后，把 Header、Payload、Signature 三个部分拼成一个字符串，每个部分之间用”点”（.）分隔，就可以返回给用户。 Base64URL&emsp;&emsp;前面提到，Header 和 Payload 串型化的算法是 Base64URL。这个算法跟 Base64算法基本类似，但有一些小的不同。 &emsp;&emsp;JWT 作为一个令牌（token），有些场合可能会放到 URL（比如 api.example.com/?token=xxx）。Base64 有三个字符+、/和=，在 URL 里面有特殊含义，所以要被替换掉：=被省略、+替换成-，/替换成_。这就是 Base64URL 算法。 案例 这里依赖于开源库auth0 12345&lt;dependency&gt; &lt;groupId&gt;com.auth0&lt;/groupId&gt; &lt;artifactId&gt;java-jwt&lt;/artifactId&gt; &lt;version&gt;3.7.0&lt;/version&gt;&lt;/dependency&gt; 用户认证请求用户提交认证请求到服务器，服务器认证用户有效性并生成签名，签名方法如下： 123456789101112131415161718192021222324252627282930313233343536public static String sign(AuthToken authToken) &#123; try &#123; logger.debug(\"begin sign token\"); //随机生成加密算法 Algorithm algorithm = generateAlgorithm(authToken); Date issuedAt = new Date(); //根据配置文件的会话超时时间计算token失效时间 Date expiresAt = DateUtils.addMinutes(issuedAt, authToken.getMaxAge()); logger.debug(\"begin build jwt builder\"); //构建jwt JWTCreator.Builder builder = JWT.create() .withIssuer(ISSUER) .withIssuedAt(issuedAt) .withExpiresAt(expiresAt) //添加主题--学号 .withSubject(authToken.getReaderBarCode()) //添加私有字段--角色 .withClaim(USER_ROLE, authToken.getUserRole()); String token = builder.sign(algorithm); logger.debug(\"sign token success &#123;0&#125;\", token); logger.debug(\"begin authToken.setRecommendId (md5hex(token)) 32 \"); logger.debug(\"begin authToken.setBeginDate\"); authToken.setBeginDate(issuedAt.getTime()); logger.debug(\"begin authToken.setExpiredDate\"); authToken.setExpiredDate(expiresAt.getTime()); return token; &#125; catch (UnsupportedEncodingException | NoSuchAlgorithmException e) &#123; logger.error(\"sing error\", e); return null; &#125;&#125; 最终服务器将token保存在缓存中并返回给浏览器，浏览器将token保存在本地，每次请求要在header中携带token参数。 用户令牌验证本例使用spring拦截器和自定义注解方式实现令牌校验。其中Auth为自定义注解。 12345678910111213141516171819202122232425@Overridepublic boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; //auth 注解判断 if (handler.getClass().isAssignableFrom(HandlerMethod.class)) &#123; Auth authToken = ((HandlerMethod) handler).getMethodAnnotation(Auth.class); if (authToken != null) &#123; //获取请求头中token字符串 String token = request.getHeader(WebAuthUtils.JWT_TOKEN); if (StringUtils.isNotEmpty(token) &amp;&amp; token.length() &gt; WebAuthUtils.JWT_TOKEN_AUTH_PREFIX.length()) &#123; //去除前缀 token = token.substring(WebAuthUtils.JWT_TOKEN_AUTH_PREFIX.length()); AuthVerificationRequest authRequest = new AuthVerificationRequest(token, authToken.acceptRole()); //验证token和角色 CertifiedUser certifiedUser = authService.verifyToken(authRequest); request.setAttribute(WebAuthUtils.WEB_READER, certifiedUser); &#125; else &#123; throw new ServiceException(ErrorCode.Common.NEED_AUTH, \"请登录\"); &#125; &#125; &#125; return super.preHandle(request, response, handler);&#125; unsign方法 12345678public static void unsign(String token, AuthToken authToken) throws UnsupportedEncodingException, NoSuchAlgorithmException, InvalidKeySpecException &#123; Algorithm algorithm = getAlgorithm(authToken); JWTVerifier verifier = JWT.require(algorithm) .withIssuer(ISSUER) .build(); //Reusable verifier instance verifier.verify(token);&#125;","categories":[{"name":"JWT","slug":"JWT","permalink":"https://legatoplay.github.io/categories/JWT/"}],"tags":[{"name":"JWT","slug":"JWT","permalink":"https://legatoplay.github.io/tags/JWT/"},{"name":"前后端分离","slug":"前后端分离","permalink":"https://legatoplay.github.io/tags/前后端分离/"}]},{"title":"HashMap实现原理及源码分析-JDK1.7","slug":"HashMap-1-7","date":"2019-04-17T01:21:36.000Z","updated":"2019-05-10T03:03:07.447Z","comments":true,"path":"2019/04/17/HashMap-1-7/","link":"","permalink":"https://legatoplay.github.io/2019/04/17/HashMap-1-7/","excerpt":"摘自：https://www.cnblogs.com/chengxiao/p/6059914.html摘自：https://www.cnblogs.com/dijia478/p/8006713.html 数据结构&emsp;&emsp;HashMap中的数据结构是数组+单链表的组合，以键值对(key-value)的形式存储元素的，通过put()和get()方法储存和获取对象。 什么是哈希表（hash table）&emsp;&emsp;在讨论哈希表之前，我们先大概了解下其他数据结构在新增，查找等基础操作执行性能 &emsp;&emsp;数组：采用一段连续的存储单元来存储数据。对于指定下标的查找，时间复杂度为O(1)；通过给定值进行查找，需要遍历数组，逐一比对给定关键字和数组元素，时间复杂度为O(n)，当然，对于有序数组，则可采用二分查找，插值查找，斐波那契查找等方式，可将查找复杂度提高为O(logn)；对于一般的插入删除操作，涉及到数组元素的移动，其平均复杂度也为O(n) &emsp;&emsp;线性链表：对于链表的新增，删除等操作（在找到指定操作位置后），仅需处理结点间的引用即可，时间复杂度为O(1)，而查找操作需要遍历链表逐一进行比对，复杂度为O(n) &emsp;&emsp;二叉树：对一棵相对平衡的有序二叉树，对其进行插入，查找，删除等操作，平均复杂度均为O(logn)。 &emsp;&emsp;哈希表：相比上述几种数据结构，在哈希表中进行添加，删除，查找等操作，性能十分之高，不考虑哈希冲突的情况下，仅需一次定位即可完成，时间复杂度为O(1)，接下来我们就来看看哈希表是如何实现达到惊艳的常数阶O(1)的。","text":"摘自：https://www.cnblogs.com/chengxiao/p/6059914.html摘自：https://www.cnblogs.com/dijia478/p/8006713.html 数据结构&emsp;&emsp;HashMap中的数据结构是数组+单链表的组合，以键值对(key-value)的形式存储元素的，通过put()和get()方法储存和获取对象。 什么是哈希表（hash table）&emsp;&emsp;在讨论哈希表之前，我们先大概了解下其他数据结构在新增，查找等基础操作执行性能 &emsp;&emsp;数组：采用一段连续的存储单元来存储数据。对于指定下标的查找，时间复杂度为O(1)；通过给定值进行查找，需要遍历数组，逐一比对给定关键字和数组元素，时间复杂度为O(n)，当然，对于有序数组，则可采用二分查找，插值查找，斐波那契查找等方式，可将查找复杂度提高为O(logn)；对于一般的插入删除操作，涉及到数组元素的移动，其平均复杂度也为O(n) &emsp;&emsp;线性链表：对于链表的新增，删除等操作（在找到指定操作位置后），仅需处理结点间的引用即可，时间复杂度为O(1)，而查找操作需要遍历链表逐一进行比对，复杂度为O(n) &emsp;&emsp;二叉树：对一棵相对平衡的有序二叉树，对其进行插入，查找，删除等操作，平均复杂度均为O(logn)。 &emsp;&emsp;哈希表：相比上述几种数据结构，在哈希表中进行添加，删除，查找等操作，性能十分之高，不考虑哈希冲突的情况下，仅需一次定位即可完成，时间复杂度为O(1)，接下来我们就来看看哈希表是如何实现达到惊艳的常数阶O(1)的。&emsp;&emsp;我们知道，数据结构的物理存储结构只有两种：顺序存储结构和链式存储结构（像栈，队列，树，图等是从逻辑结构去抽象的，映射到内存中，也这两种物理组织形式），而在上面我们提到过，在数组中根据下标查找某个元素，一次定位就可以达到，哈希表利用了这种特性，哈希表的主干就是数组。 &emsp;&emsp;比如我们要新增或查找某个元素，我们通过把当前元素的关键字 通过某个函数映射到数组中的某个位置，通过数组下标一次定位就可完成操作。 存储位置 = f(关键字) &emsp;&emsp;其中，这个函数f一般称为哈希函数，这个函数的设计好坏会直接影响到哈希表的优劣。举个例子，比如我们要在哈希表中执行插入操作： &emsp;&emsp;查找操作同理，先通过哈希函数计算出实际存储地址，然后从数组中对应地址取出即可。 哈希冲突&emsp;&emsp;然而万事无完美，如果两个不同的元素，通过哈希函数得出的实际存储地址相同怎么办？也就是说，当我们对某个元素进行哈希运算，得到一个存储地址，然后要进行插入的时候，发现已经被其他元素占用了，其实这就是所谓的哈希冲突，也叫哈希碰撞。前面我们提到过，哈希函数的设计至关重要，好的哈希函数会尽可能地保证计算简单和散列地址分布均匀,但是，我们需要清楚的是，数组是一块连续的固定长度的内存空间，再好的哈希函数也不能保证得到的存储地址绝对不发生冲突。那么哈希冲突如何解决呢？哈希冲突的解决方案有多种:开放定址法（发生冲突，继续寻找下一块未被占用的存储地址），再散列函数法，链地址法，而HashMap即是采用了链地址法，也就是数组+链表的方式。 HashMap实现原理整体结构 &emsp;&emsp;HashMap的主干是一个Entry数组。Entry是HashMap的基本组成单元，每一个Entry包含一个key-value键值对。 123456/*** The table, resized as necessary. Length MUST Always be a power of two.*///HashMap的主干数组就是一个Entry数组，初始值为空数组&#123;&#125;，主干数组的长度一定是2的n次幂transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE; &emsp;&emsp;Entry是HashMap中的一个静态内部类： 1234567891011121314151617181920212223242526272829303132333435static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final K key; V value; Entry&lt;K,V&gt; next; int hash; /** * Creates new entry. */ Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123; value = v; next = n; key = k; hash = h; &#125; //... public final boolean equals(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry e = (Map.Entry)o; Object k1 = getKey(); Object k2 = e.getKey(); if (k1 == k2 || (k1 != null &amp;&amp; k1.equals(k2))) &#123; Object v1 = getValue(); Object v2 = e.getValue(); if (v1 == v2 || (v1 != null &amp;&amp; v1.equals(v2))) return true; &#125; return false; &#125; //... &#125; &emsp;&emsp;HashMap的整体结构如下： &emsp;&emsp;简单来说，HashMap由数组+链表组成的，数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的，如果定位到的数组位置不含链表（当前entry的next指向null）,那么对于查找，添加等操作很快，仅需一次寻址即可；如果定位到的数组包含链表，对于添加操作，其时间复杂度为O(n)，首先遍历链表，存在即覆盖，否则新增；对于查找操作来讲，仍需遍历链表，然后通过key对象的equals方法逐一比对查找。所以，性能考虑，HashMap中的链表出现越少，性能才会越好。 &emsp;&emsp;其他几个重要字段 123456789101112131415161718192021222324252627282930313233 //初始容量 16 而且容量必须为2的n次幂static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16//最大容量 2^30 而且容量必须为2的n次幂static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;// 2. 负载因子(Load factor)：HashMap在其容量自动增加前可达到多满的一种尺度// a. 负载因子越大、填满的元素越多 = 空间利用率高、但冲突的机会加大、查找效率变低（因为链表变长了）// b. 负载因子越小、填满的元素越少 = 空间利用率小、冲突的机会减小、查找效率高（链表不长）static final float DEFAULT_LOAD_FACTOR = 0.75f;//空哈希表static final Entry&lt;?,?&gt;[] EMPTY_TABLE = &#123;&#125;;// 存储数据的Entry类型 数组，长度 = 2的幂// HashMap的实现方式 = 拉链法，Entry数组上的每个元素本质上是一个单向链表transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE;//HashMap的大小，即 HashMap中存储的键值对的数量transient int size;//阈值，当table == &#123;&#125;时，该值为初始容量（初始容量默认为16）；当table被填充了，也就是为table分配内存空间后，threshold一般为 capacity*loadFactory。HashMap在进行扩容时需要参考threshold，后面会详细谈到int threshold;//负载因子，代表了table的填充度有多少，默认是0.75final float loadFactor;//用于快速失败，由于HashMap非线程安全，在对HashMap进行迭代时，如果期间其他线程的参与导致HashMap的结构发生变化了（比如put，remove等操作），需要抛出异常ConcurrentModificationExceptiontransient int modCount; 构造器12345678910111213141516171819202122232425262728293031public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; threshold = initialCapacity; init();&#125;public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;public HashMap() &#123; this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR);&#125;public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this(Math.max((int) (m.size() / DEFAULT_LOAD_FACTOR) + 1, DEFAULT_INITIAL_CAPACITY), DEFAULT_LOAD_FACTOR); inflateTable(threshold); putAllForCreate(m);&#125; 注： 此处仅用于接收初始容量大小（capacity）、加载因子(Load factor)，但仍无真正初始化哈希表，即初始化存储数组table 此处先给出结论：**真正初始化哈希表（初始化存储数组table）是在第1次添加键值对时，即第1次调用put（）时。 PUT方法123456789101112131415161718192021222324252627282930313233public V put(K key, V value) &#123; // 若 哈希表未初始化（即 table为空) 则使用构造函数时设置的阈值(即初始容量)初始化数组table if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; //若key == null，则将该键-值 存放到数组table 中的第1个位置，即table [0] // 该位置永远只有1个value，新传进来的value会覆盖旧的value if (key == null) return putForNullKey(value); //根据key计算哈希值 int hash = hash(key); //根据哈希值获取要存储在数组中的索引位置 int i = indexFor(hash, table.length); //若该key已存在（即 key-value已存在 ），则用新value替换旧value for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; //若该key不存在，则将“key-value”添加到table中 modCount++; addEntry(hash, key, value, i); return null; &#125; 初始化哈希表&emsp;&emsp;inflateTable这个方法用于为主干数组table在内存中分配存储空间，通过roundUpToPowerOf2(toSize)可以确保capacity为大于或等于toSize的最接近toSize的二次幂，比如toSize=13,capacity=16;to_size=16,capacity=16;to_size=17,capacity=32. 123456789101112private void inflateTable(int toSize) &#123; //capacity一定是2的次幂,如果传入的是容量大小是19，那么转化后，初始化容量大小为32 int capacity = roundUpToPowerOf2(toSize); //重新计算阈值 threshold = 容量 * 加载因子 threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); //初始化数组 table = new Entry[capacity]; initHashSeedAsNeeded(capacity); &#125; 123456private static int roundUpToPowerOf2(int number) &#123; // assert number &gt;= 0 : \"number must be non-negative\"; return number &gt;= MAXIMUM_CAPACITY ? MAXIMUM_CAPACITY : (number &gt; 1) ? Integer.highestOneBit((number - 1) &lt;&lt; 1) : 1; &#125; &emsp;&emsp;roundUpToPowerOf2中的这段处理使得数组长度一定为2的次幂，Integer.highestOneBit是用来获取最左边的bit（其他bit位为0）所代表的数值. hash函数1234567891011121314final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125; &emsp;&emsp;以上hash函数计算出的值，通过indexFor进一步处理来获取实际的存储位置 1234static int indexFor(int h, int length) &#123; // assert Integer.bitCount(length) == 1 : \"length must be a non-zero power of 2\"; return h &amp; (length-1); &#125; &emsp;&emsp;h&amp;（length-1）保证获取的index一定在数组范围内，举个例子，默认容量16，length-1=15，h=18,转换成二进制计算为 12345 1 0 0 1 0&amp; 0 1 1 1 1__________________ 0 0 0 1 0 = 2 &emsp;&emsp;最终计算出的index=2。有些版本的对于此处的计算会使用 取模运算，也能保证index一定在数组范围内，不过位运算对计算机来说，性能更高一些（HashMap中有大量位运算）,所以最终存储位置的确定流程是这样的： 再来看看addEntry的实现： 123456789void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex); &#125; &emsp;&emsp;通过以上代码能够得知，当发生哈希冲突并且size大于阈值的时候，需要进行数组扩容，扩容时，需要新建一个长度为之前数组2倍的新的数组，然后将当前的Entry数组中的元素全部传输过去，扩容后的新数组长度为之前的2倍，所以扩容相对来说是个耗资源的操作。 插入更新示意图 为何HashMap的数组长度一定是2的次幂？12345678910111213void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; Entry[] newTable = new Entry[newCapacity]; transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1); &#125; &emsp;&emsp;如果数组进行扩容，数组长度发生变化，而存储位置 index = h&amp;(length-1),index也可能会发生变化，需要重新计算index，我们先来看看transfer这个方法 12345678910111213141516171819void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; //for循环中的代码，逐个遍历链表，重新计算索引位置，将老数组数据复制到新数组中去（数组不存储实际数据，所以仅仅是拷贝引用而已） for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); //将当前entry的next链指向新的索引位置,newTable[i]有可能为空，有可能也是个entry链，如果是entry链，直接在链表头部插入。 e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125; &#125; &emsp;&emsp;这个方法将老数组中的数据逐个链表地遍历，扔到新的扩容后的数组中，我们的数组索引位置的计算是通过 对key值的hashcode进行hash扰乱运算后，再通过和 length-1进行位运算得到最终数组索引位置。 &emsp;&emsp;hashMap的数组长度一定保持2的次幂，比如16的二进制表示为 10000，那么length-1就是15，二进制为01111，同理扩容后的数组长度为32，二进制表示为100000，length-1为31，二进制表示为011111。从下图可以我们也能看到这样会保证低位全为1，而扩容后只有一位差异，也就是多出了最左位的1，这样在通过 h&amp;(length-1)的时候，只要h对应的最左边的那一个差异位为0，就能保证得到的新的数组索引和老数组索引一致(大大减少了之前已经散列良好的老数组的数据位置重新调换)，个人理解。 &emsp;&emsp;还有，数组长度保持2的次幂，length-1的低位都为1，会使得获得的数组索引index更加均匀，比如： &emsp;&emsp;我们看到，上面的&amp;运算，高位是不会对结果产生影响的（hash函数采用各种位运算可能也是为了使得低位更加散列），我们只关注低位bit，如果低位全部为1，那么对于h低位部分来说，任何一位的变化都会对结果产生影响，也就是说，要得到index=21这个存储位置，h的低位只有这一种组合。这也是数组长度设计为必须为2的次幂的原因。 &emsp;&emsp;如果不是2的次幂，也就是低位不是全为1此时，要使得index=21，h的低位部分不再具有唯一性了，哈希冲突的几率会变的更大，同时，index对应的这个bit位无论如何不会等于1了，而对应的那些数组位置也就被白白浪费了。 GET方法12345678public V get(Object key) &#123; //如果key为null，则在table[0]结点的链表去寻找对应 key == null的键 if (key == null) return getForNullKey(); Entry&lt;K,V&gt; entry = getEntry(key); return null == entry ? null : entry.getValue(); &#125; &emsp;&emsp;get方法通过key值返回对应value，如果key为null，直接去table[0]处检索。我们再看一下getEntry这个方法 12345678910111213141516171819final Entry&lt;K,V&gt; getEntry(Object key) &#123; if (size == 0) &#123; return null; &#125; //根据key值，通过hash（）计算出对应的hash值 int hash = (key == null) ? 0 : hash(key); // 2. 根据hash值计算出对应的数组下标 // 3. 遍历 以该数组下标的数组元素为头结点的链表所有节点，寻找该key对应的值 for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; //若 hash值 &amp; key 相等，则证明该Entry=我们要的键值对 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null; &#125; &emsp;&emsp;可以看出，get方法的实现相对简单，key(hashcode)–&gt;hash–&gt;indexFor–&gt;最终索引位置，找到对应位置table[i]，再查看是否有链表，遍历链表，通过key的equals方法比对查找对应的记录。 总结数据结构 &amp; 主要参数 添加 &amp; 查询数据流程 扩容机制","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://legatoplay.github.io/categories/JAVA/"},{"name":"JAVA集合类","slug":"JAVA/JAVA集合类","permalink":"https://legatoplay.github.io/categories/JAVA/JAVA集合类/"}],"tags":[{"name":"基础知识","slug":"基础知识","permalink":"https://legatoplay.github.io/tags/基础知识/"}]},{"title":"Spring Boot (一)：自动配置实现原理一","slug":"Spring-Boot自动配置实现原理","date":"2019-03-31T14:02:23.000Z","updated":"2019-05-10T03:04:50.180Z","comments":true,"path":"2019/03/31/Spring-Boot自动配置实现原理/","link":"","permalink":"https://legatoplay.github.io/2019/03/31/Spring-Boot自动配置实现原理/","excerpt":"SpringBoot 自动配置主要通过 @EnableAutoConfiguration, @Conditional, @EnableConfigurationProperties 或者 @ConfigurationProperties等几个注解来进行自动配置完成的。 @EnableAutoConfiguration 开启自动配置，主要作用就是调用 Spring-Core 包的 loadFactoryNames()，将 autoconfig 包里的已经写好的自动配置加载进来。 @Conditional 条件注解，通过判断类路径下有没有相应配置的 jar 包来确定是否加载和自动配置这个类。 @EnableConfigurationProperties 的作用就是，给自动配置提供具体的配置参数，只需要写在 application.properties或application.yml 中，就可以通过映射写入配置类的 POJO 属性中。","text":"SpringBoot 自动配置主要通过 @EnableAutoConfiguration, @Conditional, @EnableConfigurationProperties 或者 @ConfigurationProperties等几个注解来进行自动配置完成的。 @EnableAutoConfiguration 开启自动配置，主要作用就是调用 Spring-Core 包的 loadFactoryNames()，将 autoconfig 包里的已经写好的自动配置加载进来。 @Conditional 条件注解，通过判断类路径下有没有相应配置的 jar 包来确定是否加载和自动配置这个类。 @EnableConfigurationProperties 的作用就是，给自动配置提供具体的配置参数，只需要写在 application.properties或application.yml 中，就可以通过映射写入配置类的 POJO 属性中。 @EnableAutoConfiguration事实上是通过通过Spring的@Import注释导入。 SpringBoot启动类@SpringBootApplication 进入@SpringBootApplication注解类，发现使用了注解@EnableAutoConfiguration 最终发现@EnableAutoConfiguration里使用了Spring的@Import注解导入了AutoConfigurationImportSelector类 找到selectImports()方法，它调用了getAutoConfigurationEntry方法，getAutoConfigurationEntry方法又调用了getCandidateConfigurations()方法，这个方法又调用了spring-core包中的SpringFactoriesLoader.loadFactoryNames方法。这个方法的作用是，会加载所有JAR包中的META-INF/spring.factories文件，并加载其中以EnableAutoConfiguration.class全类名为key的自动配置文件类名列表 selectImports方法12345678910111213@Overridepublic String[] selectImports(AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return NO_IMPORTS; &#125; //得到注解信息 AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader .loadMetadata(this.beanClassLoader); //得到配置配置列表 AutoConfigurationEntry autoConfigurationEntry = getAutoConfigurationEntry( autoConfigurationMetadata, annotationMetadata); return StringUtils.toStringArray(autoConfigurationEntry.getConfigurations());&#125; getAutoConfigurationEntry方法123456789101112131415161718192021222324252627282930/*** Return the &#123;@link AutoConfigurationEntry&#125; based on the &#123;@link AnnotationMetadata&#125;* of the importing &#123;@link Configuration @Configuration&#125; class.* @param autoConfigurationMetadata the auto-configuration metadata* @param annotationMetadata the annotation metadata of the configuration class* @return the auto-configurations that should be imported*/protected AutoConfigurationEntry getAutoConfigurationEntry( AutoConfigurationMetadata autoConfigurationMetadata, AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return EMPTY_ENTRY; &#125; //得到注解属性 AnnotationAttributes attributes = getAttributes(annotationMetadata); //得到候选配置列表 List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); //去重 configurations = removeDuplicates(configurations); //排序注解配置的exclude或excludeName/读取配置spring.autoconfigure.exclude Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); //调用 filter 进行过滤 OnBeanCondition/OnClassCondition/OnWebApplicationCondition configurations = filter(configurations, autoConfigurationMetadata); // fireAutoConfigurationImportEvents(configurations, exclusions); return new AutoConfigurationEntry(configurations, exclusions);&#125;","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://legatoplay.github.io/categories/JAVA/"},{"name":"Spring Boot","slug":"JAVA/Spring-Boot","permalink":"https://legatoplay.github.io/categories/JAVA/Spring-Boot/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://legatoplay.github.io/tags/Spring-Boot/"}]},{"title":"Elasticsearch 查询语法","slug":"Elasticsearch-查询语法","date":"2019-03-31T12:20:43.000Z","updated":"2019-04-16T06:33:18.563Z","comments":true,"path":"2019/03/31/Elasticsearch-查询语法/","link":"","permalink":"https://legatoplay.github.io/2019/03/31/Elasticsearch-查询语法/","excerpt":"英文文档(最新) 中文文档(2.x) 轻量检索(URL search)1GET /megacorp/employee/_search?q=last_name:Smith 参数说明详见 查询表达式Query-string 搜索通过命令非常方便地进行临时性的即席搜索 ，但它有自身的局限性（参见 轻量 搜索）。Elasticsearch 提供一个丰富灵活的查询语言叫做 查询表达式 ， 它支持构建更加复杂和健壮的查询。 领域特定语言 （DSL）， 指定了使用一个 JSON 请求。我们可以像这样重写之前的查询所有 Smith 的搜索 1234567&#123; \"query\" : &#123; \"match\" : &#123; \"last_name\" : \"Smith\" &#125; &#125;&#125;","text":"英文文档(最新) 中文文档(2.x) 轻量检索(URL search)1GET /megacorp/employee/_search?q=last_name:Smith 参数说明详见 查询表达式Query-string 搜索通过命令非常方便地进行临时性的即席搜索 ，但它有自身的局限性（参见 轻量 搜索）。Elasticsearch 提供一个丰富灵活的查询语言叫做 查询表达式 ， 它支持构建更加复杂和健壮的查询。 领域特定语言 （DSL）， 指定了使用一个 JSON 请求。我们可以像这样重写之前的查询所有 Smith 的搜索 1234567&#123; \"query\" : &#123; \"match\" : &#123; \"last_name\" : \"Smith\" &#125; &#125;&#125; 参数说明详见 from(defualt:0) &amp; size(default:10) 分页 12345&#123; \"query\": &#123; \"match_all\": &#123;&#125; &#125;, \"from\": 10, \"size\": 10 &#125; sort排序 12345678910&#123; \"query\": &#123; \"match_all\": &#123;&#125; &#125;, \"sort\" : [ &#123; \"post_date\" : &#123;\"order\" : \"asc\"&#125;&#125;, \"user\", &#123; \"name\" : \"desc\" &#125;, &#123; \"age\" : \"desc\" &#125;, \"_score\" ]&#125; 排序类型（sort order） asc 正序 desc 倒序 排序模式 (sort mode option) min 最小值 max 最大值 sum 求和 avg 求平均值 median 中间值 _soucre 显示字段 1234&#123; \"query\": &#123; \"match_all\": &#123;&#125; &#125;, \"_source\": [\"account_number\", \"balance\"]&#125; match_all 查询match_all 查询简单的 匹配所有文档。在没有指定查询方式时，它是默认的查询： 123&#123; \"query\": &#123; \"match_all\": &#123;&#125; &#125;&#125; match查询无论你在任何字段上进行的是全文搜索还是精确查询，match 查询是你可用的标准查询。如果你在一个全文字段上使用 match 查询，在执行查询前，它将用正确的分析器去分析查询字符串： 1&#123; \"match\": &#123; \"tweet\": \"About Search\" &#125;&#125; 如果在一个精确值的字段上使用它， 例如数字、日期、布尔或者一个 not_analyzed 字符串字段，那么它将会精确匹配给定的值： 1234&#123; &quot;match&quot;: &#123; &quot;age&quot;: 26 &#125;&#125;&#123; &quot;match&quot;: &#123; &quot;date&quot;: &quot;2014-09-01&quot; &#125;&#125;&#123; &quot;match&quot;: &#123; &quot;public&quot;: true &#125;&#125;&#123; &quot;match&quot;: &#123; &quot;tag&quot;: &quot;full_text&quot; &#125;&#125; multi_match 查询multi_match 查询可以在多个字段上执行相同的 match 查询： 123456&#123; \"multi_match\": &#123; \"query\": \"full text search\", \"fields\": [ \"title\", \"body\" ] &#125;&#125; range查询range 查询找出那些落在指定区间内的数字或者时间 12345678&#123; \"range\": &#123; \"age\": &#123; \"gte\": 20, \"lt\": 30 &#125; &#125;&#125; 被允许的操作符如下： gt :大于 gte :大于等于 lt :小于 lte :小于等于 term查询1234&#123; &quot;term&quot;: &#123; &quot;age&quot;: 26 &#125;&#125;&#123; &quot;term&quot;: &#123; &quot;date&quot;: &quot;2014-09-01&quot; &#125;&#125;&#123; &quot;term&quot;: &#123; &quot;public&quot;: true &#125;&#125;&#123; &quot;term&quot;: &#123; &quot;tag&quot;: &quot;full_text&quot; &#125;&#125; term 查询对于输入的文本不 分析 ，所以它将给定的值进行精确查询。 terms查询terms 查询和 term 查询一样，但它允许你指定多值进行匹配。如果这个字段包含了指定值中的任何一个值，那么这个文档满足条件： 1&#123; \"terms\": &#123; \"tag\": [ \"search\", \"full_text\", \"nosql\" ] &#125;&#125; 和term查询一样，terms查询对于输入的文本不分析。它查询那些精确匹配的值（包括在大小写、重音、空格等方面的差异）。 exists 查询和 missing 查询exists查询和missing查询被用于查找那些指定字段中有值 (exists) 或无值 (missing) 的文档。这与SQL中的IS_NULL(missing) 和NOT IS_NULL(exists) 在本质上具有共性： 12345&#123; \"exists\": &#123; \"field\": \"title\" &#125;&#125; 这些查询经常用于某个字段有值的情况和某个字段缺值的情况。 组合查询bool查询这种查询将多查询组合在一起，成为用户自己想要的布尔查询。它接收以下参数： must like and 文档必须匹配这些条件才能被包含进来。 must_not like &lt;&gt; 文档必须不匹配这些条件才能被包含进来。 should like or 如果满足这些语句中的任意语句，将增加_score，否则，无任何影响。它们主要用于修正每个文档的相关性得分。 filter 必须匹配，但它以不评分、过滤模式来进行。这些语句对评分没有贡献，只是根据过滤标准来排除或包含文档。 由于这是我们看到的第一个包含多个查询的查询，所以有必要讨论一下相关性得分是如何组合的。每一个子查询都独自地计算文档的相关性得分。一旦他们的得分被计算出来，bool查询就将这些得分进行合并并且返回一个代表整个布尔操作的得分。 下面的查询用于查找title字段匹配how to make millions并且不被标识为spam的文档。那些被标识为starred或在2014之后的文档，将比另外那些文档拥有更高的排名。如果 _两者_ 都满足，那么它排名将更高： 123456789101112&#123; \"query\": &#123; \"bool\": &#123; \"must\": &#123; \"match\": &#123; \"title\": \"how to make millions\" &#125;&#125;, \"must_not\": &#123; \"match\": &#123; \"tag\": \"spam\" &#125;&#125;, \"should\": [ &#123; \"match\": &#123; \"tag\": \"starred\" &#125;&#125;, &#123; \"range\": &#123; \"date\": &#123; \"gte\": \"2014-01-01\" &#125;&#125;&#125; ] &#125; &#125;&#125; 如果没有must语句，那么至少需要能够匹配其中的一条should语句。但，如果存在至少一条must语句，则对should语句的匹配没有要求。 带filter查询如果我们不想因为文档的时间而影响得分，可以用filter语句来重写前面的例子： 1234567891011121314&#123; \"query\":&#123; \"bool\": &#123; \"must\": &#123; \"match\": &#123; \"title\": \"how to make millions\" &#125;&#125;, \"must_not\": &#123; \"match\": &#123; \"tag\": \"spam\" &#125;&#125;, \"should\": [ &#123; \"match\": &#123; \"tag\": \"starred\" &#125;&#125; ], \"filter\": &#123; \"range\": &#123; \"date\": &#123; \"gte\": \"2014-01-01\" &#125;&#125; &#125; &#125; &#125;&#125; 通过将 range 查询移到 filter 语句中，我们将它转成不评分的查询，将不再影响文档的相关性排名。由于它现在是一个不评分的查询，可以使用各种对 filter 查询有效的优化手段来提升性能。 所有查询都可以借鉴这种方式。将查询移到 bool 查询的 filter 语句中，这样它就自动的转成一个不评分的 filter 了。 如果你需要通过多个不同的标准来过滤你的文档，bool 查询本身也可以被用做不评分的查询。简单地将它放置到 filter 语句中并在内部构建布尔逻辑： 12345678910111213141516171819202122&#123; \"query\":&#123; \"bool\": &#123; \"must\": &#123; \"match\": &#123; \"title\": \"how to make millions\" &#125;&#125;, \"must_not\": &#123; \"match\": &#123; \"tag\": \"spam\" &#125;&#125;, \"should\": [ &#123; \"match\": &#123; \"tag\": \"starred\" &#125;&#125; ], \"filter\": &#123; \"bool\": &#123; \"must\": [ &#123; \"range\": &#123; \"date\": &#123; \"gte\": \"2014-01-01\" &#125;&#125;&#125;, &#123; \"range\": &#123; \"price\": &#123; \"lte\": 29.99 &#125;&#125;&#125; ], \"must_not\": [ &#123; \"term\": &#123; \"category\": \"ebooks\" &#125;&#125; ] &#125; &#125; &#125; &#125;&#125; 聚合桶（Buckets） 满足特定条件的文档的集合 指标（Metrics） 对桶内的文档进行统计计算 这就是全部了！每个聚合都是一个或者多个桶和零个或者多个指标的组合。翻译成粗略的SQL语句来解释吧： 123SELECT COUNT(color) FROM tableGROUP BY color COUNT(color) 相当于指标。 GROUP BY color 相当于桶。 桶在概念上类似于 SQL 的分组（GROUP BY），而指标则类似于 COUNT() 、 SUM() 、 MAX() 等统计方法。1234567891011&#123; \"aggs\": &#123; \"sales_over_time\": &#123; \"date_histogram\": &#123; \"field\": \"processDate\", \"interval\": \"year\", \"format\": \"yyyy\" &#125; &#125; &#125;&#125;","categories":[{"name":"Elastic","slug":"Elastic","permalink":"https://legatoplay.github.io/categories/Elastic/"}],"tags":[{"name":"Elastic","slug":"Elastic","permalink":"https://legatoplay.github.io/tags/Elastic/"}]},{"title":"Database Change Notification + AQ 基于流的表变化通知","slug":"Database-Change-Notification","date":"2019-03-28T07:09:40.000Z","updated":"2019-05-10T03:03:54.987Z","comments":true,"path":"2019/03/28/Database-Change-Notification/","link":"","permalink":"https://legatoplay.github.io/2019/03/28/Database-Change-Notification/","excerpt":"Streams Advanced Queuing User’s Guide(pl/sql)Database JDBC Developer’s GuideOracle高级队列介绍 Database Change Notification’docs-jdbc-styleDCN plsql-styleCQN 设置消息队列","text":"Streams Advanced Queuing User’s Guide(pl/sql)Database JDBC Developer’s GuideOracle高级队列介绍 Database Change Notification’docs-jdbc-styleDCN plsql-styleCQN 设置消息队列 1 用户授权12345CONNECT / AS SYSDBA;GRANT EXECUTE ON DBMS_AQ to GDLISNET;GRANT EXECUTE ON DBMS_AQADM to GDLISNET;GRANT AQ_ADMINISTRATOR_ROLE TO GDLISNET;--GRANT ADMINISTER DATABASE TRIGGER TO GDLISNET; 2 创建队列表1234567891011121314151617begin dbms_aqadm.drop_queue_table(queue_table =&gt; &apos;CATALOG_AQ_TABLE&apos;, force =&gt; true);end;/begin dbms_aqadm.create_queue_table( queue_table =&gt; &apos;GDLISNET.CATALOG_AQ_TABLE&apos;, queue_payload_type =&gt; &apos;sys.aq$_jms_text_message&apos;, sort_list =&gt; &apos;ENQ_TIME&apos;, compatible =&gt; &apos;10.0.0&apos;, primary_instance =&gt; 0, secondary_instance =&gt; 0, comment =&gt; &apos;主键码变化队列表&apos;, storage_clause =&gt; &apos;tablespace GDLISNET_TABLE pctfree 10 initrans 1 maxtrans 255 storage ( initial 64K next 1M minextents 1 maxextents unlimited )&apos;);end;/ 3 创建队列123456789101112131415begin dbms_aqadm.drop_queue(queue_name =&gt; &apos;CATALOG_AQ&apos;);end;/begin dbms_aqadm.create_queue( queue_name =&gt; &apos;GDLISNET.CATALOG_AQ&apos;, queue_table =&gt; &apos;GDLISNET.CATALOG_AQ_TABLE&apos;, queue_type =&gt; sys.dbms_aqadm.normal_queue, max_retries =&gt; 5, retry_delay =&gt; 120, retention_time =&gt; 0, comment =&gt; &apos;主键码变化队列&apos;);end;/ 4 创建存储过程1234567891011121314151617181920212223242526272829303132333435363738394041424344454647CREATE OR REPLACE PROCEDURE ENQUEUE_CATALOG_AQ(main_Key NUMBER, table_name NVARCHAR2, operation number) authid current_user isbegin declare text varchar2(200); message sys.aq$_jms_text_message; enqueue_options dbms_aq.enqueue_options_t; message_properties dbms_aq.message_properties_t; msgid raw(16); row_count number; select_count_str VARCHAR2(800) := &apos;&apos;; v_errmsg varchar2(1000); begin message := sys.aq$_jms_text_message.construct; message.set_type(&apos;&apos;); message.set_userid(&apos;gdlisnet&apos;); message.set_appid(&apos;plsql_enq&apos;); message.set_groupid(&apos;&apos;); text := &apos;&#123;&apos; || &apos;&quot;mainKey&quot;:&apos; || main_Key || &apos;,&apos; || &apos;&quot;tableName&quot;:&quot;&apos; || table_name || &apos;&quot;,&apos; || &apos;&quot;operation&quot;:&apos; || operation || &apos;&#125;&apos;; message.set_text(text); select_count_str := &apos;select count(*) as raw_count from catalog_aq_table t where instr(t.user_data.text_vc,:1)&gt;0&apos;; EXECUTE IMMEDIATE select_count_str into row_count using text; --prc_wlf_sys_writelog(2, 4, &apos;ENQUEUE_CATALOG_AQ&apos;, row_count, &apos;&apos;); if (row_count = 0) then dbms_aq.enqueue(queue_name =&gt; &apos;GDLISNET.CATALOG_AQ&apos;, enqueue_options =&gt; enqueue_options, message_properties =&gt; message_properties, payload =&gt; message, msgid =&gt; msgid); end if; commit; EXCEPTION when others then /*v_errmsg := &apos;sqlexception~~sqlcode:&apos; || to_char(sqlcode) || &apos; sqlstate:&apos; || substr(sqlerrm, 1, 512); prc_wlf_sys_writelog(2, 4, &apos;ENQUEUE_CATALOG_AQ&apos;, v_errmsg, &apos;&apos;);*/ DBMS_OUTPUT.PUT_LINE(&apos;你的数据更新语句失败了!&apos;); end;end ENQUEUE_CATALOG_AQ; 5 启动队列123begin dbms_aqadm.start_queue(queue_name =&gt; &apos;CATALOG_AQ&apos;);end; 6 停止队列123begin dbms_aqadm.stop_queue(queue_name =&gt; &apos;CATALOG_AQ&apos;);end; 7 入队测试1234567begin enqueue_catalog_aq(ROW_ID =&gt; &apos;1111&apos;, table_name =&gt; &apos;馆藏书目库&apos;, operation =&gt; 4);end;select * from catalog_aq_table; 8 出队1234567891011121314151617181920SET SERVEROUTPUT ONDECLAREdequeue_options DBMS_AQ.dequeue_options_t;message_properties DBMS_AQ.message_properties_t;message_handle RAW(16);message sys.aq$_jms_text_message;text VARCHAR2(200);BEGIN dequeue_options.navigation := DBMS_AQ.FIRST_MESSAGE; DBMS_AQ.DEQUEUE( queue_name =&gt; &apos;gdlisnet.CATALOG_AQ&apos;, dequeue_options =&gt; dequeue_options, message_properties =&gt; message_properties, payload =&gt; message, msgid =&gt; message_handle); message.get_text(text); DBMS_OUTPUT.PUT_LINE(&apos;Text: &apos;||text); COMMIT;END;/ 9 删除队列顺序停止队列–》删除队列-》删除queue_table 注册表变化通知（DCN）此部分只通知insert和update 变化 1 用户授权123CONNECT / AS SYSDBA;GRANT CHANGE NOTIFICATION TO gdlisnet;GRANT EXECUTE ON DBMS_CHANGE_NOTIFICATION TO gdlisnet; 2 修改用户线程数123CONNECT / AS SYSDBA;--Rem Enable job queue processes to receive notifications.ALTER SYSTEM SET &quot;job_queue_processes&quot;=2; 3 创建存储过程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748CREATE OR REPLACE PROCEDURE chnf_callback(ntfnds IN cq_notification$_descriptor) AS regid NUMBER; tbname VARCHAR2(60); event_type NUMBER; numtables NUMBER; operation_type NUMBER; numrows NUMBER; row_id VARCHAR2(20); mainKey NUMBER; selectMainKeyStr VARCHAR2(800) := &apos;&apos;;BEGIN regid := ntfnds.registration_id; numtables := ntfnds.numtables; event_type := ntfnds.event_type; --INSERT INTO nfevents VALUES (regid, event_type); IF (event_type = DBMS_CHANGE_NOTIFICATION.EVENT_OBJCHANGE) THEN FOR i IN 1 .. numtables LOOP tbname := ntfnds.table_desc_array(i).table_name; operation_type := ntfnds.table_desc_array(I) . Opflags; --INSERT INTO nftablechanges VALUES (regid, tbname, operation_type); /* Send the table name and operation_type to client side listener using UTL_HTTP */ /* If interested in the rowids, obtain them as follows */ IF (bitand(operation_type, DBMS_CHANGE_NOTIFICATION.ALL_ROWS) = 0) THEN numrows := ntfnds.table_desc_array(i).numrows; ELSE numrows := 0; /* ROWID INFO NOT AVAILABLE */ END IF; /* The body of the loop is not executed when numrows is ZERO */ FOR j IN 1 .. numrows LOOP Row_id := ntfnds.table_desc_array(i).row_desc_array(j).row_id; --INSERT INTO nfrowchanges VALUES (regid, tbname, Row_id); selectMainKeyStr := &apos;select 主键码 from &apos; || tbname || &apos; where rowid=:1&apos;; EXECUTE IMMEDIATE selectMainKeyStr into mainKey using row_id; gdlisnet.enqueue_catalog_aq(ROW_ID =&gt; mainKey, table_name =&gt; tbname, operation =&gt; operation_type); /* optionally Send out row_ids to client side listener using UTL_HTTP; */ END LOOP; END LOOP; END IF; COMMIT;END; 4 注册1234567891011121314151617181920212223DECLARE REGDS CQ_NOTIFICATION$_REG_INFO; regid NUMBER; mgr_id NUMBER; dept_id NUMBER; qosflags NUMBER; operations_filter NUMBER;BEGIN qosflags := DBMS_CHANGE_NOTIFICATION.QOS_RELIABLE + DBMS_CHANGE_NOTIFICATION.QOS_ROWIDS; operations_filter := DBMS_CHANGE_NOTIFICATION.INSERTOP + DBMS_CHANGE_NOTIFICATION.UPDATEOP; REGDS := cq_notification$_reg_info(&apos;chnf_callback&apos;, qosflags, 0, operations_filter, 0); regid := DBMS_CHANGE_NOTIFICATION.NEW_REG_START(REGDS); SELECT 主键码 INTO mgr_id FROM 馆藏书目库 WHERE rownum = 1; SELECT 主键码 INTO mgr_id FROM 馆藏典藏库 WHERE rownum = 1; SELECT 主键码 INTO mgr_id FROM 采购库 WHERE rownum = 1; DBMS_CHANGE_NOTIFICATION.REG_END;END; 5 解除注册1call DBMS_CHANGE_NOTIFICATION.DEREGISTER (regid IN NUMBER); 存储过程增加日志方法1 创建日志表12345678910111213141516171819202122232425262728293031323334-- Create tablecreate table TBL_WLF_SYS_LOG( s_time VARCHAR2(32) not null, s_level VARCHAR2(32), s_procname VARCHAR2(64), s_msg VARCHAR2(4000), s_advice VARCHAR2(1024))tablespace GDLISNET_TABLE pctfree 10 initrans 1 maxtrans 255 storage ( initial 64K next 1M minextents 1 maxextents unlimited );-- Add comments to the table comment on table TBL_WLF_SYS_LOG is &apos;存储过程日志表&apos;;-- Add comments to the columns comment on column TBL_WLF_SYS_LOG.s_time is &apos;操作时间&apos;;comment on column TBL_WLF_SYS_LOG.s_level is &apos;操作级别&apos;;comment on column TBL_WLF_SYS_LOG.s_procname is &apos;执行存储过程名称&apos;;comment on column TBL_WLF_SYS_LOG.s_msg is &apos;错误信息&apos;;comment on column TBL_WLF_SYS_LOG.s_advice is &apos;建议信息&apos;; 创建写日志存储过程12345678910111213141516171819202122232425262728293031323334353637383940414243444546CREATE OR REPLACE PROCEDURE prc_wlf_sys_writelog(i_flag INTEGER, i_id INTEGER, str_procname varchar2, str_msg varchar2, str_advice varchar2) IS -- 操作时间 str_time varchar2(32); -- 操作级别 str_level varchar2(32); -- 执行存储过程名称 p_procname varchar2(1024); -- 错误信息，或者记录信息 p_msg varchar2(1024); -- 建议信息 p_advice varchar2(1024);BEGIN IF (i_flag = 2 AND i_id &gt;= 1 AND i_id &lt;= 4) THEN CASE WHEN i_id = 1 THEN str_level := &apos;log&apos;; WHEN i_id = 2 THEN str_level := &apos;debug&apos;; WHEN i_id = 3 THEN str_level := &apos;alarm&apos;; ELSE str_level := &apos;error&apos;; END CASE; p_procname := str_procname; p_msg := str_msg; p_advice := str_advice; ELSE str_level := &apos;error&apos;; p_procname := &apos;p_public_writelog&apos;; p_msg := &apos;writelog_error&apos;; p_advice := &apos;&apos;; END IF; str_time := to_char(SYSDATE, &apos;yyyy-mm-dd hh24:mi:ss&apos;); INSERT INTO tbl_wlf_sys_log (s_time, s_level, s_procname, s_msg, s_advice) VALUES (str_time, str_level, p_procname, p_msg, p_advice); COMMIT;END prc_wlf_sys_writelog; 调用存储过程中加入异常捕获，并调用prc_wlf_sys_writelog做日志调用12345EXCEPTION when others then v_errmsg := &apos;sqlexception~~sqlcode:&apos; || to_char(sqlcode) || &apos; sqlstate:&apos; || substr(sqlerrm, 1, 512); prc_wlf_sys_writelog(2, 4, &apos;ENQUEUE_CATALOG_AQ&apos;, v_errmsg, &apos;&apos;);","categories":[{"name":"数据库","slug":"数据库","permalink":"https://legatoplay.github.io/categories/数据库/"}],"tags":[{"name":"Oracle","slug":"Oracle","permalink":"https://legatoplay.github.io/tags/Oracle/"}]},{"title":"Hexo 简单使用","slug":"Hexo-简单使用","date":"2019-03-28T06:35:10.000Z","updated":"2019-04-17T09:06:12.645Z","comments":true,"path":"2019/03/28/Hexo-简单使用/","link":"","permalink":"https://legatoplay.github.io/2019/03/28/Hexo-简单使用/","excerpt":"npm安装 1npm install hexo -g 查看版本号 1hexo -v","text":"npm安装 1npm install hexo -g 查看版本号 1hexo -v 初始化项目 1hexo init 发布 1hexo g 启动 1hexo server -p 8080 创建新页面 1hexo new post \"***\" 发布到github 安装github发布扩展 1npm install hexo-deployer-git --save 配置__config.yml，末尾添加 123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repository: git@github.com:legatoplay/legatoplay.github.io.git branch: master 发布到github 1hexo d -g","categories":[{"name":"前端","slug":"前端","permalink":"https://legatoplay.github.io/categories/前端/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://legatoplay.github.io/tags/Hexo/"},{"name":"JS","slug":"JS","permalink":"https://legatoplay.github.io/tags/JS/"}]},{"title":"JAVA 类加载机制","slug":"JAVA-类加载机制","date":"2017-11-05T06:10:10.000Z","updated":"2019-05-10T03:02:15.503Z","comments":true,"path":"2017/11/05/JAVA-类加载机制/","link":"","permalink":"https://legatoplay.github.io/2017/11/05/JAVA-类加载机制/","excerpt":"摘自：https://blog.csdn.net/qq_16216221/article/details/71600535摘自：http://www.importnew.com/25295.html摘自：https://blog.csdn.net/noaman_wgs/article/details/74489549摘自：https://www.cnblogs.com/ityouknow/p/5603287.html 一、概述&emsp;&emsp;类加载是Java程序运行的第一步，研究类的加载有助于了解JVM执行过程，并指导开发者采取更有效的措施配合程序执行，对理解java虚拟机的连接模型和java语言的动态性都有很大帮助。 &emsp;&emsp;JVM中类的装载是由类加载器（ClassLoader）和它的子类来实现的，Java中的类加载器是一个重要的Java运行时系统组件，它负责在运行时查找和装入类文件中的类。 &emsp;&emsp;由于Java的跨平台性，经过编译的Java源程序并不是一个可执行程序，而是一个或多个类文件。当Java程序需要使用某个类时，JVM会确保这个类已经被加载、连接（验证、准备和解析）和初始化。","text":"摘自：https://blog.csdn.net/qq_16216221/article/details/71600535摘自：http://www.importnew.com/25295.html摘自：https://blog.csdn.net/noaman_wgs/article/details/74489549摘自：https://www.cnblogs.com/ityouknow/p/5603287.html 一、概述&emsp;&emsp;类加载是Java程序运行的第一步，研究类的加载有助于了解JVM执行过程，并指导开发者采取更有效的措施配合程序执行，对理解java虚拟机的连接模型和java语言的动态性都有很大帮助。 &emsp;&emsp;JVM中类的装载是由类加载器（ClassLoader）和它的子类来实现的，Java中的类加载器是一个重要的Java运行时系统组件，它负责在运行时查找和装入类文件中的类。 &emsp;&emsp;由于Java的跨平台性，经过编译的Java源程序并不是一个可执行程序，而是一个或多个类文件。当Java程序需要使用某个类时，JVM会确保这个类已经被加载、连接（验证、准备和解析）和初始化。 1.1 什么是类的加载&emsp;&emsp;类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在堆区创建一个java.lang.Class对象，用来封装类在方法区内的数据结构。类的加载的最终产品是位于堆区中的Class对象，Class对象封装了类在方法区内的数据结构，并且向Java程序员提供了访问方法区内的数据结构的接口。 &emsp;&emsp;类加载器并不需要等到某个类被“首次主动使用”时再加载它，JVM规范允许类加载器在预料某个类将要被使用时就预先加载它，如果在预先加载的过程中遇到了.class文件缺失或存在错误，类加载器必须在程序首次主动使用该类时才报告错误（LinkageError错误）如果这个类一直没有被程序主动使用，那么类加载器就不会报告错误。 二、类的加载过程 &emsp;&emsp;其中类加载的过程包括了加载、验证、准备、解析、初始化五个阶段。在这五个阶段中，加载、验证、准备和初始化这四个阶段发生的顺序是确定的，而解析阶段则不一定，它在某些情况下可以在初始化阶段之后开始，这是为了支持Java语言的运行时绑定（也成为动态绑定或晚期绑定）。另外注意这里的几个阶段是按顺序开始，而不是按顺序进行或完成，因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段。 2.1. 加载 &emsp;&emsp;加载主要是将.class文件（并不一定是.class。可以是ZIP包，网络中获取）中的二进制字节流读入到JVM中。 &emsp;&emsp;在加载阶段，JVM需要完成3件事： &emsp;&emsp;&emsp;1）通过类的全限定名获取该类的二进制字节流； &emsp;&emsp;&emsp;2）将字节流所代表的静态存储结构转化为方法区的运行时数据结构； &emsp;&emsp;&emsp;3）在内存中生成一个该类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。 &emsp;&emsp;加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中，而且在Java堆中也创建一个java.lang.Class类的对象（运行时的类型信息），这样便可以通过该对象访问方法区中的这些数据。 2.2 连接2.2.1. 验证&emsp;&emsp;验证是连接阶段的第一步，主要确保加载进来的字节流符合JVM规范。&emsp;&emsp;验证阶段会完成以下4个阶段的检验动作：&emsp;&emsp;&emsp;1）文件格式验证&emsp;&emsp;&emsp;2）元数据验证(是否符合Java语言规范)&emsp;&emsp;&emsp;3）字节码验证（确定程序语义合法，符合逻辑）&emsp;&emsp;&emsp;4）符号引用验证（确保下一步的解析能正常执行） 2.2.2. 准备&emsp;&emsp;准备阶段是正式为类变量分配内存并设置类变量的初始值阶段，即在方法区中分配这些变量所使用的内存空间。注意这里所说的初始值概念，比如一个类变量定义为： 1public static int v = 8080; &emsp;&emsp;实际上变量v在准备阶段过后的初始值为0而不是8080，将v赋值为8080的putstatic指令是程序被编译后，存放于类构造器方法之中。但是注意如果声明为： 1public static final int v = 8080; &emsp;&emsp;在编译阶段会为v生成ConstantValue属性，在准备阶段虚拟机会根据ConstantValue属性将v赋值为8080。 2.2.3. 解析&emsp;&emsp;解析阶段是指虚拟机将常量池中的符号引用替换为直接引用的过程。符号引用就是class文件中的： 123CONSTANT_Class_infoCONSTANT_Field_infoCONSTANT_Method_info 等类型的常量。下面我们解释一下符号引用和直接引用的概念：&emsp;&emsp;符号引用与虚拟机实现的布局无关，引用的目标并不一定要已经加载到内存中。各种虚拟机实现的内存布局可以各不相同，但是它们能接受的符号引用必须是一致的，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。&emsp;&emsp;直接引用可以是指向目标的指针，相对偏移量或是一个能间接定位到目标的句柄。如果有了直接引用，那引用的目标必定已经在内存中存在。 2.3 初始化&emsp;&emsp;初始化阶段是类加载过程的最后一步，主要是根据程序中的赋值语句主动为类变量赋值。 &emsp;&emsp;&emsp;注： &emsp;&emsp;&emsp;1）当有父类且父类为初始化的时候，先去初始化父类；&emsp;&emsp;&emsp;2）再进行子类初始化语句。 三、Jvm加载的过程图例 什么时候需要对类进行初始化？1）使用new该类实例化对象的时候；2）读取或设置类静态字段的时候（但被final修饰的字段，在编译器时就被放入常量池的静态字段除外static final）；3）调用类静态方法的时候；4）使用反射Class.forName(“xxxx”)对类进行反射调用的时候，该类需要初始化；5）初始化一个类的时候，有父类，先初始化父类（注：1. 接口除外，父接口在调用的时候才会被初始化；2.子类引用父类静态字段，只会引发父类初始化）；6）被标明为启动类的类（即包含main()方法的类）要初始化；7）当使用JDK1.7的动态语言支持时，如果一个java.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。 什么时候不会初始化？1）通过子类引用父类的静态字段，只会触发父类的初始化，而不会触发子类的初始化。2）定义对象数组，不会触发该类的初始化。3）常量在编译期间会存入调用类的常量池中，本质上并没有直接引用定义常量的类，不会触发定义常量所在的类。4）通过类名获取Class对象，不会触发类的初始化。5）通过Class.forName加载指定类时，如果指定参数initialize为false时，也不会触发类初始化，其实这个参数是告诉虚拟机，是否要对类进行初始化。6）通过ClassLoader默认的loadClass方法，也不会触发初始化动作。 四、类加载器类加载器负责对类的加载，加载类的方式有：1）从本地系统直接加载2）通过网络下载.class文件3）从zip，jar等归档文件中加载.class文件4）从专有数据库中提取.class文件5）将Java源文件动态编译为.class文件（服务器）","categories":[{"name":"JAVA","slug":"JAVA","permalink":"https://legatoplay.github.io/categories/JAVA/"},{"name":"类加载机制","slug":"JAVA/类加载机制","permalink":"https://legatoplay.github.io/categories/JAVA/类加载机制/"}],"tags":[{"name":"基础知识","slug":"基础知识","permalink":"https://legatoplay.github.io/tags/基础知识/"}]}]}