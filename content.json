{"meta":{"title":"Gary's Blog","subtitle":null,"description":"主攻JAVA。","author":"Gary","url":"https://legatoplay.github.io","root":"/"},"pages":[{"title":"categories","date":"2018-08-06T03:45:31.000Z","updated":"2019-04-16T06:33:18.601Z","comments":true,"path":"categories/index.html","permalink":"https://legatoplay.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-08-06T03:44:56.000Z","updated":"2019-04-16T06:33:18.604Z","comments":true,"path":"tags/index.html","permalink":"https://legatoplay.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"HashMap实现原理及源码分析-JDK1.7","slug":"HashMap-1-7","date":"2019-04-17T01:21:36.000Z","updated":"2019-04-17T06:43:17.522Z","comments":true,"path":"2019/04/17/HashMap-1-7/","link":"","permalink":"https://legatoplay.github.io/2019/04/17/HashMap-1-7/","excerpt":"摘自：https://www.cnblogs.com/chengxiao/p/6059914.html摘自：https://www.cnblogs.com/dijia478/p/8006713.html 数据结构&emsp;&emsp;HashMap中的数据结构是数组+单链表的组合，以键值对(key-value)的形式存储元素的，通过put()和get()方法储存和获取对象。 什么是哈希表（hash table）&emsp;&emsp;在讨论哈希表之前，我们先大概了解下其他数据结构在新增，查找等基础操作执行性能 &emsp;&emsp;数组：采用一段连续的存储单元来存储数据。对于指定下标的查找，时间复杂度为O(1)；通过给定值进行查找，需要遍历数组，逐一比对给定关键字和数组元素，时间复杂度为O(n)，当然，对于有序数组，则可采用二分查找，插值查找，斐波那契查找等方式，可将查找复杂度提高为O(logn)；对于一般的插入删除操作，涉及到数组元素的移动，其平均复杂度也为O(n) &emsp;&emsp;线性链表：对于链表的新增，删除等操作（在找到指定操作位置后），仅需处理结点间的引用即可，时间复杂度为O(1)，而查找操作需要遍历链表逐一进行比对，复杂度为O(n) &emsp;&emsp;二叉树：对一棵相对平衡的有序二叉树，对其进行插入，查找，删除等操作，平均复杂度均为O(logn)。 &emsp;&emsp;哈希表：相比上述几种数据结构，在哈希表中进行添加，删除，查找等操作，性能十分之高，不考虑哈希冲突的情况下，仅需一次定位即可完成，时间复杂度为O(1)，接下来我们就来看看哈希表是如何实现达到惊艳的常数阶O(1)的。","text":"摘自：https://www.cnblogs.com/chengxiao/p/6059914.html摘自：https://www.cnblogs.com/dijia478/p/8006713.html 数据结构&emsp;&emsp;HashMap中的数据结构是数组+单链表的组合，以键值对(key-value)的形式存储元素的，通过put()和get()方法储存和获取对象。 什么是哈希表（hash table）&emsp;&emsp;在讨论哈希表之前，我们先大概了解下其他数据结构在新增，查找等基础操作执行性能 &emsp;&emsp;数组：采用一段连续的存储单元来存储数据。对于指定下标的查找，时间复杂度为O(1)；通过给定值进行查找，需要遍历数组，逐一比对给定关键字和数组元素，时间复杂度为O(n)，当然，对于有序数组，则可采用二分查找，插值查找，斐波那契查找等方式，可将查找复杂度提高为O(logn)；对于一般的插入删除操作，涉及到数组元素的移动，其平均复杂度也为O(n) &emsp;&emsp;线性链表：对于链表的新增，删除等操作（在找到指定操作位置后），仅需处理结点间的引用即可，时间复杂度为O(1)，而查找操作需要遍历链表逐一进行比对，复杂度为O(n) &emsp;&emsp;二叉树：对一棵相对平衡的有序二叉树，对其进行插入，查找，删除等操作，平均复杂度均为O(logn)。 &emsp;&emsp;哈希表：相比上述几种数据结构，在哈希表中进行添加，删除，查找等操作，性能十分之高，不考虑哈希冲突的情况下，仅需一次定位即可完成，时间复杂度为O(1)，接下来我们就来看看哈希表是如何实现达到惊艳的常数阶O(1)的。&emsp;&emsp;我们知道，数据结构的物理存储结构只有两种：顺序存储结构和链式存储结构（像栈，队列，树，图等是从逻辑结构去抽象的，映射到内存中，也这两种物理组织形式），而在上面我们提到过，在数组中根据下标查找某个元素，一次定位就可以达到，哈希表利用了这种特性，哈希表的主干就是数组。 &emsp;&emsp;比如我们要新增或查找某个元素，我们通过把当前元素的关键字 通过某个函数映射到数组中的某个位置，通过数组下标一次定位就可完成操作。 存储位置 = f(关键字) &emsp;&emsp;其中，这个函数f一般称为哈希函数，这个函数的设计好坏会直接影响到哈希表的优劣。举个例子，比如我们要在哈希表中执行插入操作： &emsp;&emsp;查找操作同理，先通过哈希函数计算出实际存储地址，然后从数组中对应地址取出即可。 哈希冲突&emsp;&emsp;然而万事无完美，如果两个不同的元素，通过哈希函数得出的实际存储地址相同怎么办？也就是说，当我们对某个元素进行哈希运算，得到一个存储地址，然后要进行插入的时候，发现已经被其他元素占用了，其实这就是所谓的哈希冲突，也叫哈希碰撞。前面我们提到过，哈希函数的设计至关重要，好的哈希函数会尽可能地保证计算简单和散列地址分布均匀,但是，我们需要清楚的是，数组是一块连续的固定长度的内存空间，再好的哈希函数也不能保证得到的存储地址绝对不发生冲突。那么哈希冲突如何解决呢？哈希冲突的解决方案有多种:开放定址法（发生冲突，继续寻找下一块未被占用的存储地址），再散列函数法，链地址法，而HashMap即是采用了链地址法，也就是数组+链表的方式。 HashMap实现原理整体结构 &emsp;&emsp;HashMap的主干是一个Entry数组。Entry是HashMap的基本组成单元，每一个Entry包含一个key-value键值对。 123456/*** The table, resized as necessary. Length MUST Always be a power of two.*///HashMap的主干数组就是一个Entry数组，初始值为空数组&#123;&#125;，主干数组的长度一定是2的n次幂transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE; &emsp;&emsp;Entry是HashMap中的一个静态内部类： 1234567891011121314151617181920212223242526272829303132333435static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final K key; V value; Entry&lt;K,V&gt; next; int hash; /** * Creates new entry. */ Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123; value = v; next = n; key = k; hash = h; &#125; //... public final boolean equals(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry e = (Map.Entry)o; Object k1 = getKey(); Object k2 = e.getKey(); if (k1 == k2 || (k1 != null &amp;&amp; k1.equals(k2))) &#123; Object v1 = getValue(); Object v2 = e.getValue(); if (v1 == v2 || (v1 != null &amp;&amp; v1.equals(v2))) return true; &#125; return false; &#125; //... &#125; &emsp;&emsp;HashMap的整体结构如下： &emsp;&emsp;简单来说，HashMap由数组+链表组成的，数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的，如果定位到的数组位置不含链表（当前entry的next指向null）,那么对于查找，添加等操作很快，仅需一次寻址即可；如果定位到的数组包含链表，对于添加操作，其时间复杂度为O(n)，首先遍历链表，存在即覆盖，否则新增；对于查找操作来讲，仍需遍历链表，然后通过key对象的equals方法逐一比对查找。所以，性能考虑，HashMap中的链表出现越少，性能才会越好。 &emsp;&emsp;其他几个重要字段 123456789101112131415161718192021222324252627282930313233 //初始容量 16 而且容量必须为2的n次幂static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16//最大容量 2^30 而且容量必须为2的n次幂static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;// 2. 负载因子(Load factor)：HashMap在其容量自动增加前可达到多满的一种尺度// a. 负载因子越大、填满的元素越多 = 空间利用率高、但冲突的机会加大、查找效率变低（因为链表变长了）// b. 负载因子越小、填满的元素越少 = 空间利用率小、冲突的机会减小、查找效率高（链表不长）static final float DEFAULT_LOAD_FACTOR = 0.75f;//空哈希表static final Entry&lt;?,?&gt;[] EMPTY_TABLE = &#123;&#125;;// 存储数据的Entry类型 数组，长度 = 2的幂// HashMap的实现方式 = 拉链法，Entry数组上的每个元素本质上是一个单向链表transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE;//HashMap的大小，即 HashMap中存储的键值对的数量transient int size;//阈值，当table == &#123;&#125;时，该值为初始容量（初始容量默认为16）；当table被填充了，也就是为table分配内存空间后，threshold一般为 capacity*loadFactory。HashMap在进行扩容时需要参考threshold，后面会详细谈到int threshold;//负载因子，代表了table的填充度有多少，默认是0.75final float loadFactor;//用于快速失败，由于HashMap非线程安全，在对HashMap进行迭代时，如果期间其他线程的参与导致HashMap的结构发生变化了（比如put，remove等操作），需要抛出异常ConcurrentModificationExceptiontransient int modCount; 构造器12345678910111213141516171819202122232425262728293031public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; threshold = initialCapacity; init();&#125;public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;public HashMap() &#123; this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR);&#125;public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this(Math.max((int) (m.size() / DEFAULT_LOAD_FACTOR) + 1, DEFAULT_INITIAL_CAPACITY), DEFAULT_LOAD_FACTOR); inflateTable(threshold); putAllForCreate(m);&#125; 注： 此处仅用于接收初始容量大小（capacity）、加载因子(Load factor)，但仍无真正初始化哈希表，即初始化存储数组table 此处先给出结论：**真正初始化哈希表（初始化存储数组table）是在第1次添加键值对时，即第1次调用put（）时。 PUT方法123456789101112131415161718192021222324252627282930313233public V put(K key, V value) &#123; // 若 哈希表未初始化（即 table为空) 则使用构造函数时设置的阈值(即初始容量)初始化数组table if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; //若key == null，则将该键-值 存放到数组table 中的第1个位置，即table [0] // 该位置永远只有1个value，新传进来的value会覆盖旧的value if (key == null) return putForNullKey(value); //根据key计算哈希值 int hash = hash(key); //根据哈希值获取要存储在数组中的索引位置 int i = indexFor(hash, table.length); //若该key已存在（即 key-value已存在 ），则用新value替换旧value for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; //若该key不存在，则将“key-value”添加到table中 modCount++; addEntry(hash, key, value, i); return null; &#125; 初始化哈希表&emsp;&emsp;inflateTable这个方法用于为主干数组table在内存中分配存储空间，通过roundUpToPowerOf2(toSize)可以确保capacity为大于或等于toSize的最接近toSize的二次幂，比如toSize=13,capacity=16;to_size=16,capacity=16;to_size=17,capacity=32. 123456789101112private void inflateTable(int toSize) &#123; //capacity一定是2的次幂,如果传入的是容量大小是19，那么转化后，初始化容量大小为32 int capacity = roundUpToPowerOf2(toSize); //重新计算阈值 threshold = 容量 * 加载因子 threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); //初始化数组 table = new Entry[capacity]; initHashSeedAsNeeded(capacity); &#125; 123456private static int roundUpToPowerOf2(int number) &#123; // assert number &gt;= 0 : \"number must be non-negative\"; return number &gt;= MAXIMUM_CAPACITY ? MAXIMUM_CAPACITY : (number &gt; 1) ? Integer.highestOneBit((number - 1) &lt;&lt; 1) : 1; &#125; &emsp;&emsp;roundUpToPowerOf2中的这段处理使得数组长度一定为2的次幂，Integer.highestOneBit是用来获取最左边的bit（其他bit位为0）所代表的数值. hash函数1234567891011121314final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125; &emsp;&emsp;以上hash函数计算出的值，通过indexFor进一步处理来获取实际的存储位置 1234static int indexFor(int h, int length) &#123; // assert Integer.bitCount(length) == 1 : \"length must be a non-zero power of 2\"; return h &amp; (length-1); &#125; &emsp;&emsp;h&amp;（length-1）保证获取的index一定在数组范围内，举个例子，默认容量16，length-1=15，h=18,转换成二进制计算为 12345 1 0 0 1 0&amp; 0 1 1 1 1__________________ 0 0 0 1 0 = 2 &emsp;&emsp;最终计算出的index=2。有些版本的对于此处的计算会使用 取模运算，也能保证index一定在数组范围内，不过位运算对计算机来说，性能更高一些（HashMap中有大量位运算）,所以最终存储位置的确定流程是这样的： 再来看看addEntry的实现： 123456789void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex); &#125; &emsp;&emsp;通过以上代码能够得知，当发生哈希冲突并且size大于阈值的时候，需要进行数组扩容，扩容时，需要新建一个长度为之前数组2倍的新的数组，然后将当前的Entry数组中的元素全部传输过去，扩容后的新数组长度为之前的2倍，所以扩容相对来说是个耗资源的操作。 插入更新示意图 为何HashMap的数组长度一定是2的次幂？12345678910111213void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; Entry[] newTable = new Entry[newCapacity]; transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1); &#125; &emsp;&emsp;如果数组进行扩容，数组长度发生变化，而存储位置 index = h&amp;(length-1),index也可能会发生变化，需要重新计算index，我们先来看看transfer这个方法 12345678910111213141516171819void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; //for循环中的代码，逐个遍历链表，重新计算索引位置，将老数组数据复制到新数组中去（数组不存储实际数据，所以仅仅是拷贝引用而已） for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); //将当前entry的next链指向新的索引位置,newTable[i]有可能为空，有可能也是个entry链，如果是entry链，直接在链表头部插入。 e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125; &#125; &emsp;&emsp;这个方法将老数组中的数据逐个链表地遍历，扔到新的扩容后的数组中，我们的数组索引位置的计算是通过 对key值的hashcode进行hash扰乱运算后，再通过和 length-1进行位运算得到最终数组索引位置。 &emsp;&emsp;hashMap的数组长度一定保持2的次幂，比如16的二进制表示为 10000，那么length-1就是15，二进制为01111，同理扩容后的数组长度为32，二进制表示为100000，length-1为31，二进制表示为011111。从下图可以我们也能看到这样会保证低位全为1，而扩容后只有一位差异，也就是多出了最左位的1，这样在通过 h&amp;(length-1)的时候，只要h对应的最左边的那一个差异位为0，就能保证得到的新的数组索引和老数组索引一致(大大减少了之前已经散列良好的老数组的数据位置重新调换)，个人理解。 &emsp;&emsp;还有，数组长度保持2的次幂，length-1的低位都为1，会使得获得的数组索引index更加均匀，比如： &emsp;&emsp;我们看到，上面的&amp;运算，高位是不会对结果产生影响的（hash函数采用各种位运算可能也是为了使得低位更加散列），我们只关注低位bit，如果低位全部为1，那么对于h低位部分来说，任何一位的变化都会对结果产生影响，也就是说，要得到index=21这个存储位置，h的低位只有这一种组合。这也是数组长度设计为必须为2的次幂的原因。 &emsp;&emsp;如果不是2的次幂，也就是低位不是全为1此时，要使得index=21，h的低位部分不再具有唯一性了，哈希冲突的几率会变的更大，同时，index对应的这个bit位无论如何不会等于1了，而对应的那些数组位置也就被白白浪费了。 GET方法12345678public V get(Object key) &#123; //如果key为null，则在table[0]结点的链表去寻找对应 key == null的键 if (key == null) return getForNullKey(); Entry&lt;K,V&gt; entry = getEntry(key); return null == entry ? null : entry.getValue(); &#125; &emsp;&emsp;get方法通过key值返回对应value，如果key为null，直接去table[0]处检索。我们再看一下getEntry这个方法 12345678910111213141516171819final Entry&lt;K,V&gt; getEntry(Object key) &#123; if (size == 0) &#123; return null; &#125; //根据key值，通过hash（）计算出对应的hash值 int hash = (key == null) ? 0 : hash(key); // 2. 根据hash值计算出对应的数组下标 // 3. 遍历 以该数组下标的数组元素为头结点的链表所有节点，寻找该key对应的值 for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; //若 hash值 &amp; key 相等，则证明该Entry=我们要的键值对 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null; &#125; &emsp;&emsp;可以看出，get方法的实现相对简单，key(hashcode)–&gt;hash–&gt;indexFor–&gt;最终索引位置，找到对应位置table[i]，再查看是否有链表，遍历链表，通过key的equals方法比对查找对应的记录。 总结数据结构 &amp; 主要参数 添加 &amp; 查询数据流程 扩容机制","categories":[{"name":"基础知识","slug":"基础知识","permalink":"https://legatoplay.github.io/categories/基础知识/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://legatoplay.github.io/tags/JAVA/"},{"name":"JAVA集合类","slug":"JAVA集合类","permalink":"https://legatoplay.github.io/tags/JAVA集合类/"}]},{"title":"Spring Boot (一)：自动配置实现原理一","slug":"Spring-Boot自动配置实现原理","date":"2019-03-31T14:02:23.000Z","updated":"2019-04-16T06:49:18.932Z","comments":true,"path":"2019/03/31/Spring-Boot自动配置实现原理/","link":"","permalink":"https://legatoplay.github.io/2019/03/31/Spring-Boot自动配置实现原理/","excerpt":"SpringBoot 自动配置主要通过 @EnableAutoConfiguration, @Conditional, @EnableConfigurationProperties 或者 @ConfigurationProperties等几个注解来进行自动配置完成的。 @EnableAutoConfiguration 开启自动配置，主要作用就是调用 Spring-Core 包的 loadFactoryNames()，将 autoconfig 包里的已经写好的自动配置加载进来。 @Conditional 条件注解，通过判断类路径下有没有相应配置的 jar 包来确定是否加载和自动配置这个类。 @EnableConfigurationProperties 的作用就是，给自动配置提供具体的配置参数，只需要写在 application.properties或application.yml 中，就可以通过映射写入配置类的 POJO 属性中。","text":"SpringBoot 自动配置主要通过 @EnableAutoConfiguration, @Conditional, @EnableConfigurationProperties 或者 @ConfigurationProperties等几个注解来进行自动配置完成的。 @EnableAutoConfiguration 开启自动配置，主要作用就是调用 Spring-Core 包的 loadFactoryNames()，将 autoconfig 包里的已经写好的自动配置加载进来。 @Conditional 条件注解，通过判断类路径下有没有相应配置的 jar 包来确定是否加载和自动配置这个类。 @EnableConfigurationProperties 的作用就是，给自动配置提供具体的配置参数，只需要写在 application.properties或application.yml 中，就可以通过映射写入配置类的 POJO 属性中。 @EnableAutoConfiguration事实上是通过通过Spring的@Import注释导入。 SpringBoot启动类@SpringBootApplication 进入@SpringBootApplication注解类，发现使用了注解@EnableAutoConfiguration 最终发现@EnableAutoConfiguration里使用了Spring的@Import注解导入了AutoConfigurationImportSelector类 找到selectImports()方法，它调用了getAutoConfigurationEntry方法，getAutoConfigurationEntry方法又调用了getCandidateConfigurations()方法，这个方法又调用了spring-core包中的SpringFactoriesLoader.loadFactoryNames方法。这个方法的作用是，会加载所有JAR包中的META-INF/spring.factories文件，并加载其中以EnableAutoConfiguration.class全类名为key的自动配置文件类名列表 selectImports方法12345678910111213@Overridepublic String[] selectImports(AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return NO_IMPORTS; &#125; //得到注解信息 AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader .loadMetadata(this.beanClassLoader); //得到配置配置列表 AutoConfigurationEntry autoConfigurationEntry = getAutoConfigurationEntry( autoConfigurationMetadata, annotationMetadata); return StringUtils.toStringArray(autoConfigurationEntry.getConfigurations());&#125; getAutoConfigurationEntry方法123456789101112131415161718192021222324252627282930/*** Return the &#123;@link AutoConfigurationEntry&#125; based on the &#123;@link AnnotationMetadata&#125;* of the importing &#123;@link Configuration @Configuration&#125; class.* @param autoConfigurationMetadata the auto-configuration metadata* @param annotationMetadata the annotation metadata of the configuration class* @return the auto-configurations that should be imported*/protected AutoConfigurationEntry getAutoConfigurationEntry( AutoConfigurationMetadata autoConfigurationMetadata, AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return EMPTY_ENTRY; &#125; //得到注解属性 AnnotationAttributes attributes = getAttributes(annotationMetadata); //得到候选配置列表 List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); //去重 configurations = removeDuplicates(configurations); //排序注解配置的exclude或excludeName/读取配置spring.autoconfigure.exclude Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); //调用 filter 进行过滤 OnBeanCondition/OnClassCondition/OnWebApplicationCondition configurations = filter(configurations, autoConfigurationMetadata); // fireAutoConfigurationImportEvents(configurations, exclusions); return new AutoConfigurationEntry(configurations, exclusions);&#125;","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://legatoplay.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://legatoplay.github.io/tags/Spring-Boot/"}]},{"title":"Elasticsearch 查询语法","slug":"Elasticsearch-查询语法","date":"2019-03-31T12:20:43.000Z","updated":"2019-04-16T06:33:18.563Z","comments":true,"path":"2019/03/31/Elasticsearch-查询语法/","link":"","permalink":"https://legatoplay.github.io/2019/03/31/Elasticsearch-查询语法/","excerpt":"英文文档(最新) 中文文档(2.x) 轻量检索(URL search)1GET /megacorp/employee/_search?q=last_name:Smith 参数说明详见 查询表达式Query-string 搜索通过命令非常方便地进行临时性的即席搜索 ，但它有自身的局限性（参见 轻量 搜索）。Elasticsearch 提供一个丰富灵活的查询语言叫做 查询表达式 ， 它支持构建更加复杂和健壮的查询。 领域特定语言 （DSL）， 指定了使用一个 JSON 请求。我们可以像这样重写之前的查询所有 Smith 的搜索 1234567&#123; \"query\" : &#123; \"match\" : &#123; \"last_name\" : \"Smith\" &#125; &#125;&#125;","text":"英文文档(最新) 中文文档(2.x) 轻量检索(URL search)1GET /megacorp/employee/_search?q=last_name:Smith 参数说明详见 查询表达式Query-string 搜索通过命令非常方便地进行临时性的即席搜索 ，但它有自身的局限性（参见 轻量 搜索）。Elasticsearch 提供一个丰富灵活的查询语言叫做 查询表达式 ， 它支持构建更加复杂和健壮的查询。 领域特定语言 （DSL）， 指定了使用一个 JSON 请求。我们可以像这样重写之前的查询所有 Smith 的搜索 1234567&#123; \"query\" : &#123; \"match\" : &#123; \"last_name\" : \"Smith\" &#125; &#125;&#125; 参数说明详见 from(defualt:0) &amp; size(default:10) 分页 12345&#123; \"query\": &#123; \"match_all\": &#123;&#125; &#125;, \"from\": 10, \"size\": 10 &#125; sort排序 12345678910&#123; \"query\": &#123; \"match_all\": &#123;&#125; &#125;, \"sort\" : [ &#123; \"post_date\" : &#123;\"order\" : \"asc\"&#125;&#125;, \"user\", &#123; \"name\" : \"desc\" &#125;, &#123; \"age\" : \"desc\" &#125;, \"_score\" ]&#125; 排序类型（sort order） asc 正序 desc 倒序 排序模式 (sort mode option) min 最小值 max 最大值 sum 求和 avg 求平均值 median 中间值 _soucre 显示字段 1234&#123; \"query\": &#123; \"match_all\": &#123;&#125; &#125;, \"_source\": [\"account_number\", \"balance\"]&#125; match_all 查询match_all 查询简单的 匹配所有文档。在没有指定查询方式时，它是默认的查询： 123&#123; \"query\": &#123; \"match_all\": &#123;&#125; &#125;&#125; match查询无论你在任何字段上进行的是全文搜索还是精确查询，match 查询是你可用的标准查询。如果你在一个全文字段上使用 match 查询，在执行查询前，它将用正确的分析器去分析查询字符串： 1&#123; \"match\": &#123; \"tweet\": \"About Search\" &#125;&#125; 如果在一个精确值的字段上使用它， 例如数字、日期、布尔或者一个 not_analyzed 字符串字段，那么它将会精确匹配给定的值： 1234&#123; &quot;match&quot;: &#123; &quot;age&quot;: 26 &#125;&#125;&#123; &quot;match&quot;: &#123; &quot;date&quot;: &quot;2014-09-01&quot; &#125;&#125;&#123; &quot;match&quot;: &#123; &quot;public&quot;: true &#125;&#125;&#123; &quot;match&quot;: &#123; &quot;tag&quot;: &quot;full_text&quot; &#125;&#125; multi_match 查询multi_match 查询可以在多个字段上执行相同的 match 查询： 123456&#123; \"multi_match\": &#123; \"query\": \"full text search\", \"fields\": [ \"title\", \"body\" ] &#125;&#125; range查询range 查询找出那些落在指定区间内的数字或者时间 12345678&#123; \"range\": &#123; \"age\": &#123; \"gte\": 20, \"lt\": 30 &#125; &#125;&#125; 被允许的操作符如下： gt :大于 gte :大于等于 lt :小于 lte :小于等于 term查询1234&#123; &quot;term&quot;: &#123; &quot;age&quot;: 26 &#125;&#125;&#123; &quot;term&quot;: &#123; &quot;date&quot;: &quot;2014-09-01&quot; &#125;&#125;&#123; &quot;term&quot;: &#123; &quot;public&quot;: true &#125;&#125;&#123; &quot;term&quot;: &#123; &quot;tag&quot;: &quot;full_text&quot; &#125;&#125; term 查询对于输入的文本不 分析 ，所以它将给定的值进行精确查询。 terms查询terms 查询和 term 查询一样，但它允许你指定多值进行匹配。如果这个字段包含了指定值中的任何一个值，那么这个文档满足条件： 1&#123; \"terms\": &#123; \"tag\": [ \"search\", \"full_text\", \"nosql\" ] &#125;&#125; 和term查询一样，terms查询对于输入的文本不分析。它查询那些精确匹配的值（包括在大小写、重音、空格等方面的差异）。 exists 查询和 missing 查询exists查询和missing查询被用于查找那些指定字段中有值 (exists) 或无值 (missing) 的文档。这与SQL中的IS_NULL(missing) 和NOT IS_NULL(exists) 在本质上具有共性： 12345&#123; \"exists\": &#123; \"field\": \"title\" &#125;&#125; 这些查询经常用于某个字段有值的情况和某个字段缺值的情况。 组合查询bool查询这种查询将多查询组合在一起，成为用户自己想要的布尔查询。它接收以下参数： must like and 文档必须匹配这些条件才能被包含进来。 must_not like &lt;&gt; 文档必须不匹配这些条件才能被包含进来。 should like or 如果满足这些语句中的任意语句，将增加_score，否则，无任何影响。它们主要用于修正每个文档的相关性得分。 filter 必须匹配，但它以不评分、过滤模式来进行。这些语句对评分没有贡献，只是根据过滤标准来排除或包含文档。 由于这是我们看到的第一个包含多个查询的查询，所以有必要讨论一下相关性得分是如何组合的。每一个子查询都独自地计算文档的相关性得分。一旦他们的得分被计算出来，bool查询就将这些得分进行合并并且返回一个代表整个布尔操作的得分。 下面的查询用于查找title字段匹配how to make millions并且不被标识为spam的文档。那些被标识为starred或在2014之后的文档，将比另外那些文档拥有更高的排名。如果 _两者_ 都满足，那么它排名将更高： 123456789101112&#123; \"query\": &#123; \"bool\": &#123; \"must\": &#123; \"match\": &#123; \"title\": \"how to make millions\" &#125;&#125;, \"must_not\": &#123; \"match\": &#123; \"tag\": \"spam\" &#125;&#125;, \"should\": [ &#123; \"match\": &#123; \"tag\": \"starred\" &#125;&#125;, &#123; \"range\": &#123; \"date\": &#123; \"gte\": \"2014-01-01\" &#125;&#125;&#125; ] &#125; &#125;&#125; 如果没有must语句，那么至少需要能够匹配其中的一条should语句。但，如果存在至少一条must语句，则对should语句的匹配没有要求。 带filter查询如果我们不想因为文档的时间而影响得分，可以用filter语句来重写前面的例子： 1234567891011121314&#123; \"query\":&#123; \"bool\": &#123; \"must\": &#123; \"match\": &#123; \"title\": \"how to make millions\" &#125;&#125;, \"must_not\": &#123; \"match\": &#123; \"tag\": \"spam\" &#125;&#125;, \"should\": [ &#123; \"match\": &#123; \"tag\": \"starred\" &#125;&#125; ], \"filter\": &#123; \"range\": &#123; \"date\": &#123; \"gte\": \"2014-01-01\" &#125;&#125; &#125; &#125; &#125;&#125; 通过将 range 查询移到 filter 语句中，我们将它转成不评分的查询，将不再影响文档的相关性排名。由于它现在是一个不评分的查询，可以使用各种对 filter 查询有效的优化手段来提升性能。 所有查询都可以借鉴这种方式。将查询移到 bool 查询的 filter 语句中，这样它就自动的转成一个不评分的 filter 了。 如果你需要通过多个不同的标准来过滤你的文档，bool 查询本身也可以被用做不评分的查询。简单地将它放置到 filter 语句中并在内部构建布尔逻辑： 12345678910111213141516171819202122&#123; \"query\":&#123; \"bool\": &#123; \"must\": &#123; \"match\": &#123; \"title\": \"how to make millions\" &#125;&#125;, \"must_not\": &#123; \"match\": &#123; \"tag\": \"spam\" &#125;&#125;, \"should\": [ &#123; \"match\": &#123; \"tag\": \"starred\" &#125;&#125; ], \"filter\": &#123; \"bool\": &#123; \"must\": [ &#123; \"range\": &#123; \"date\": &#123; \"gte\": \"2014-01-01\" &#125;&#125;&#125;, &#123; \"range\": &#123; \"price\": &#123; \"lte\": 29.99 &#125;&#125;&#125; ], \"must_not\": [ &#123; \"term\": &#123; \"category\": \"ebooks\" &#125;&#125; ] &#125; &#125; &#125; &#125;&#125; 聚合桶（Buckets） 满足特定条件的文档的集合 指标（Metrics） 对桶内的文档进行统计计算 这就是全部了！每个聚合都是一个或者多个桶和零个或者多个指标的组合。翻译成粗略的SQL语句来解释吧： 123SELECT COUNT(color) FROM tableGROUP BY color COUNT(color) 相当于指标。 GROUP BY color 相当于桶。 桶在概念上类似于 SQL 的分组（GROUP BY），而指标则类似于 COUNT() 、 SUM() 、 MAX() 等统计方法。1234567891011&#123; \"aggs\": &#123; \"sales_over_time\": &#123; \"date_histogram\": &#123; \"field\": \"processDate\", \"interval\": \"year\", \"format\": \"yyyy\" &#125; &#125; &#125;&#125;","categories":[{"name":"Elastic","slug":"Elastic","permalink":"https://legatoplay.github.io/categories/Elastic/"}],"tags":[{"name":"Elastic","slug":"Elastic","permalink":"https://legatoplay.github.io/tags/Elastic/"}]},{"title":"Database Change Notification + AQ 基于流的表变化通知","slug":"Database-Change-Notification","date":"2019-03-28T07:09:40.000Z","updated":"2019-04-16T07:42:48.723Z","comments":true,"path":"2019/03/28/Database-Change-Notification/","link":"","permalink":"https://legatoplay.github.io/2019/03/28/Database-Change-Notification/","excerpt":"Streams Advanced Queuing User’s Guide(pl/sql)Database JDBC Developer’s GuideOracle高级队列介绍 Database Change Notification’docs-jdbc-styleDCN plsql-styleCQN 设置消息队列","text":"Streams Advanced Queuing User’s Guide(pl/sql)Database JDBC Developer’s GuideOracle高级队列介绍 Database Change Notification’docs-jdbc-styleDCN plsql-styleCQN 设置消息队列 1 用户授权12345CONNECT / AS SYSDBA;GRANT EXECUTE ON DBMS_AQ to GDLISNET;GRANT EXECUTE ON DBMS_AQADM to GDLISNET;GRANT AQ_ADMINISTRATOR_ROLE TO GDLISNET;--GRANT ADMINISTER DATABASE TRIGGER TO GDLISNET; 2 创建队列表1234567891011121314151617begin dbms_aqadm.drop_queue_table(queue_table =&gt; &apos;CATALOG_AQ_TABLE&apos;, force =&gt; true);end;/begin dbms_aqadm.create_queue_table( queue_table =&gt; &apos;GDLISNET.CATALOG_AQ_TABLE&apos;, queue_payload_type =&gt; &apos;sys.aq$_jms_text_message&apos;, sort_list =&gt; &apos;ENQ_TIME&apos;, compatible =&gt; &apos;10.0.0&apos;, primary_instance =&gt; 0, secondary_instance =&gt; 0, comment =&gt; &apos;主键码变化队列表&apos;, storage_clause =&gt; &apos;tablespace GDLISNET_TABLE pctfree 10 initrans 1 maxtrans 255 storage ( initial 64K next 1M minextents 1 maxextents unlimited )&apos;);end;/ 3 创建队列123456789101112131415begin dbms_aqadm.drop_queue(queue_name =&gt; &apos;CATALOG_AQ&apos;);end;/begin dbms_aqadm.create_queue( queue_name =&gt; &apos;GDLISNET.CATALOG_AQ&apos;, queue_table =&gt; &apos;GDLISNET.CATALOG_AQ_TABLE&apos;, queue_type =&gt; sys.dbms_aqadm.normal_queue, max_retries =&gt; 5, retry_delay =&gt; 120, retention_time =&gt; 0, comment =&gt; &apos;主键码变化队列&apos;);end;/ 4 创建存储过程1234567891011121314151617181920212223242526272829303132333435363738394041424344454647CREATE OR REPLACE PROCEDURE ENQUEUE_CATALOG_AQ(main_Key NUMBER, table_name NVARCHAR2, operation number) authid current_user isbegin declare text varchar2(200); message sys.aq$_jms_text_message; enqueue_options dbms_aq.enqueue_options_t; message_properties dbms_aq.message_properties_t; msgid raw(16); row_count number; select_count_str VARCHAR2(800) := &apos;&apos;; v_errmsg varchar2(1000); begin message := sys.aq$_jms_text_message.construct; message.set_type(&apos;&apos;); message.set_userid(&apos;gdlisnet&apos;); message.set_appid(&apos;plsql_enq&apos;); message.set_groupid(&apos;&apos;); text := &apos;&#123;&apos; || &apos;&quot;mainKey&quot;:&apos; || main_Key || &apos;,&apos; || &apos;&quot;tableName&quot;:&quot;&apos; || table_name || &apos;&quot;,&apos; || &apos;&quot;operation&quot;:&apos; || operation || &apos;&#125;&apos;; message.set_text(text); select_count_str := &apos;select count(*) as raw_count from catalog_aq_table t where instr(t.user_data.text_vc,:1)&gt;0&apos;; EXECUTE IMMEDIATE select_count_str into row_count using text; --prc_wlf_sys_writelog(2, 4, &apos;ENQUEUE_CATALOG_AQ&apos;, row_count, &apos;&apos;); if (row_count = 0) then dbms_aq.enqueue(queue_name =&gt; &apos;GDLISNET.CATALOG_AQ&apos;, enqueue_options =&gt; enqueue_options, message_properties =&gt; message_properties, payload =&gt; message, msgid =&gt; msgid); end if; commit; EXCEPTION when others then /*v_errmsg := &apos;sqlexception~~sqlcode:&apos; || to_char(sqlcode) || &apos; sqlstate:&apos; || substr(sqlerrm, 1, 512); prc_wlf_sys_writelog(2, 4, &apos;ENQUEUE_CATALOG_AQ&apos;, v_errmsg, &apos;&apos;);*/ DBMS_OUTPUT.PUT_LINE(&apos;你的数据更新语句失败了!&apos;); end;end ENQUEUE_CATALOG_AQ; 5 启动队列123begin dbms_aqadm.start_queue(queue_name =&gt; &apos;CATALOG_AQ&apos;);end; 6 停止队列123begin dbms_aqadm.stop_queue(queue_name =&gt; &apos;CATALOG_AQ&apos;);end; 7 入队测试1234567begin enqueue_catalog_aq(ROW_ID =&gt; &apos;1111&apos;, table_name =&gt; &apos;馆藏书目库&apos;, operation =&gt; 4);end;select * from catalog_aq_table; 8 出队1234567891011121314151617181920SET SERVEROUTPUT ONDECLAREdequeue_options DBMS_AQ.dequeue_options_t;message_properties DBMS_AQ.message_properties_t;message_handle RAW(16);message sys.aq$_jms_text_message;text VARCHAR2(200);BEGIN dequeue_options.navigation := DBMS_AQ.FIRST_MESSAGE; DBMS_AQ.DEQUEUE( queue_name =&gt; &apos;gdlisnet.CATALOG_AQ&apos;, dequeue_options =&gt; dequeue_options, message_properties =&gt; message_properties, payload =&gt; message, msgid =&gt; message_handle); message.get_text(text); DBMS_OUTPUT.PUT_LINE(&apos;Text: &apos;||text); COMMIT;END;/ 9 删除队列顺序停止队列–》删除队列-》删除queue_table 注册表变化通知（DCN）此部分只通知insert和update 变化 1 用户授权123CONNECT / AS SYSDBA;GRANT CHANGE NOTIFICATION TO gdlisnet;GRANT EXECUTE ON DBMS_CHANGE_NOTIFICATION TO gdlisnet; 2 修改用户线程数123CONNECT / AS SYSDBA;--Rem Enable job queue processes to receive notifications.ALTER SYSTEM SET &quot;job_queue_processes&quot;=2; 3 创建存储过程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748CREATE OR REPLACE PROCEDURE chnf_callback(ntfnds IN cq_notification$_descriptor) AS regid NUMBER; tbname VARCHAR2(60); event_type NUMBER; numtables NUMBER; operation_type NUMBER; numrows NUMBER; row_id VARCHAR2(20); mainKey NUMBER; selectMainKeyStr VARCHAR2(800) := &apos;&apos;;BEGIN regid := ntfnds.registration_id; numtables := ntfnds.numtables; event_type := ntfnds.event_type; --INSERT INTO nfevents VALUES (regid, event_type); IF (event_type = DBMS_CHANGE_NOTIFICATION.EVENT_OBJCHANGE) THEN FOR i IN 1 .. numtables LOOP tbname := ntfnds.table_desc_array(i).table_name; operation_type := ntfnds.table_desc_array(I) . Opflags; --INSERT INTO nftablechanges VALUES (regid, tbname, operation_type); /* Send the table name and operation_type to client side listener using UTL_HTTP */ /* If interested in the rowids, obtain them as follows */ IF (bitand(operation_type, DBMS_CHANGE_NOTIFICATION.ALL_ROWS) = 0) THEN numrows := ntfnds.table_desc_array(i).numrows; ELSE numrows := 0; /* ROWID INFO NOT AVAILABLE */ END IF; /* The body of the loop is not executed when numrows is ZERO */ FOR j IN 1 .. numrows LOOP Row_id := ntfnds.table_desc_array(i).row_desc_array(j).row_id; --INSERT INTO nfrowchanges VALUES (regid, tbname, Row_id); selectMainKeyStr := &apos;select 主键码 from &apos; || tbname || &apos; where rowid=:1&apos;; EXECUTE IMMEDIATE selectMainKeyStr into mainKey using row_id; gdlisnet.enqueue_catalog_aq(ROW_ID =&gt; mainKey, table_name =&gt; tbname, operation =&gt; operation_type); /* optionally Send out row_ids to client side listener using UTL_HTTP; */ END LOOP; END LOOP; END IF; COMMIT;END; 4 注册1234567891011121314151617181920212223DECLARE REGDS CQ_NOTIFICATION$_REG_INFO; regid NUMBER; mgr_id NUMBER; dept_id NUMBER; qosflags NUMBER; operations_filter NUMBER;BEGIN qosflags := DBMS_CHANGE_NOTIFICATION.QOS_RELIABLE + DBMS_CHANGE_NOTIFICATION.QOS_ROWIDS; operations_filter := DBMS_CHANGE_NOTIFICATION.INSERTOP + DBMS_CHANGE_NOTIFICATION.UPDATEOP; REGDS := cq_notification$_reg_info(&apos;chnf_callback&apos;, qosflags, 0, operations_filter, 0); regid := DBMS_CHANGE_NOTIFICATION.NEW_REG_START(REGDS); SELECT 主键码 INTO mgr_id FROM 馆藏书目库 WHERE rownum = 1; SELECT 主键码 INTO mgr_id FROM 馆藏典藏库 WHERE rownum = 1; SELECT 主键码 INTO mgr_id FROM 采购库 WHERE rownum = 1; DBMS_CHANGE_NOTIFICATION.REG_END;END; 5 解除注册1call DBMS_CHANGE_NOTIFICATION.DEREGISTER (regid IN NUMBER); 存储过程增加日志方法1 创建日志表12345678910111213141516171819202122232425262728293031323334-- Create tablecreate table TBL_WLF_SYS_LOG( s_time VARCHAR2(32) not null, s_level VARCHAR2(32), s_procname VARCHAR2(64), s_msg VARCHAR2(4000), s_advice VARCHAR2(1024))tablespace GDLISNET_TABLE pctfree 10 initrans 1 maxtrans 255 storage ( initial 64K next 1M minextents 1 maxextents unlimited );-- Add comments to the table comment on table TBL_WLF_SYS_LOG is &apos;存储过程日志表&apos;;-- Add comments to the columns comment on column TBL_WLF_SYS_LOG.s_time is &apos;操作时间&apos;;comment on column TBL_WLF_SYS_LOG.s_level is &apos;操作级别&apos;;comment on column TBL_WLF_SYS_LOG.s_procname is &apos;执行存储过程名称&apos;;comment on column TBL_WLF_SYS_LOG.s_msg is &apos;错误信息&apos;;comment on column TBL_WLF_SYS_LOG.s_advice is &apos;建议信息&apos;; 创建写日志存储过程12345678910111213141516171819202122232425262728293031323334353637383940414243444546CREATE OR REPLACE PROCEDURE prc_wlf_sys_writelog(i_flag INTEGER, i_id INTEGER, str_procname varchar2, str_msg varchar2, str_advice varchar2) IS -- 操作时间 str_time varchar2(32); -- 操作级别 str_level varchar2(32); -- 执行存储过程名称 p_procname varchar2(1024); -- 错误信息，或者记录信息 p_msg varchar2(1024); -- 建议信息 p_advice varchar2(1024);BEGIN IF (i_flag = 2 AND i_id &gt;= 1 AND i_id &lt;= 4) THEN CASE WHEN i_id = 1 THEN str_level := &apos;log&apos;; WHEN i_id = 2 THEN str_level := &apos;debug&apos;; WHEN i_id = 3 THEN str_level := &apos;alarm&apos;; ELSE str_level := &apos;error&apos;; END CASE; p_procname := str_procname; p_msg := str_msg; p_advice := str_advice; ELSE str_level := &apos;error&apos;; p_procname := &apos;p_public_writelog&apos;; p_msg := &apos;writelog_error&apos;; p_advice := &apos;&apos;; END IF; str_time := to_char(SYSDATE, &apos;yyyy-mm-dd hh24:mi:ss&apos;); INSERT INTO tbl_wlf_sys_log (s_time, s_level, s_procname, s_msg, s_advice) VALUES (str_time, str_level, p_procname, p_msg, p_advice); COMMIT;END prc_wlf_sys_writelog; 调用存储过程中加入异常捕获，并调用prc_wlf_sys_writelog做日志调用12345EXCEPTION when others then v_errmsg := &apos;sqlexception~~sqlcode:&apos; || to_char(sqlcode) || &apos; sqlstate:&apos; || substr(sqlerrm, 1, 512); prc_wlf_sys_writelog(2, 4, &apos;ENQUEUE_CATALOG_AQ&apos;, v_errmsg, &apos;&apos;);","categories":[],"tags":[{"name":"Oracle","slug":"Oracle","permalink":"https://legatoplay.github.io/tags/Oracle/"}]},{"title":"Hexo 简单使用","slug":"Hexo-简单使用","date":"2019-03-28T06:35:10.000Z","updated":"2019-04-16T06:33:18.564Z","comments":true,"path":"2019/03/28/Hexo-简单使用/","link":"","permalink":"https://legatoplay.github.io/2019/03/28/Hexo-简单使用/","excerpt":"npm安装 1npm install hexo -g 查看版本号 1hexo -v","text":"npm安装 1npm install hexo -g 查看版本号 1hexo -v 初始化项目 1hexo init 发布 1hexo g 启动 1hexo server -p 8080 创建新页面 1hexo new post \"***\" 发布到github 安装github发布扩展 1npm install hexo-deployer-git --save 配置__config.yml，末尾添加 123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repository: git@github.com:legatoplay/legatoplay.github.io.git branch: master 发布到github 1hexo d -g","categories":[{"name":"前端","slug":"前端","permalink":"https://legatoplay.github.io/categories/前端/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://legatoplay.github.io/tags/Hexo/"},{"name":"JS","slug":"JS","permalink":"https://legatoplay.github.io/tags/JS/"}]},{"title":"JAVA 类加载机制","slug":"JAVA-类加载机制","date":"2017-11-05T06:10:10.000Z","updated":"2019-04-16T07:39:32.153Z","comments":true,"path":"2017/11/05/JAVA-类加载机制/","link":"","permalink":"https://legatoplay.github.io/2017/11/05/JAVA-类加载机制/","excerpt":"摘自：https://blog.csdn.net/qq_16216221/article/details/71600535摘自：http://www.importnew.com/25295.html摘自：https://blog.csdn.net/noaman_wgs/article/details/74489549摘自：https://www.cnblogs.com/ityouknow/p/5603287.html 一、概述&emsp;&emsp;类加载是Java程序运行的第一步，研究类的加载有助于了解JVM执行过程，并指导开发者采取更有效的措施配合程序执行，对理解java虚拟机的连接模型和java语言的动态性都有很大帮助。 &emsp;&emsp;JVM中类的装载是由类加载器（ClassLoader）和它的子类来实现的，Java中的类加载器是一个重要的Java运行时系统组件，它负责在运行时查找和装入类文件中的类。 &emsp;&emsp;由于Java的跨平台性，经过编译的Java源程序并不是一个可执行程序，而是一个或多个类文件。当Java程序需要使用某个类时，JVM会确保这个类已经被加载、连接（验证、准备和解析）和初始化。","text":"摘自：https://blog.csdn.net/qq_16216221/article/details/71600535摘自：http://www.importnew.com/25295.html摘自：https://blog.csdn.net/noaman_wgs/article/details/74489549摘自：https://www.cnblogs.com/ityouknow/p/5603287.html 一、概述&emsp;&emsp;类加载是Java程序运行的第一步，研究类的加载有助于了解JVM执行过程，并指导开发者采取更有效的措施配合程序执行，对理解java虚拟机的连接模型和java语言的动态性都有很大帮助。 &emsp;&emsp;JVM中类的装载是由类加载器（ClassLoader）和它的子类来实现的，Java中的类加载器是一个重要的Java运行时系统组件，它负责在运行时查找和装入类文件中的类。 &emsp;&emsp;由于Java的跨平台性，经过编译的Java源程序并不是一个可执行程序，而是一个或多个类文件。当Java程序需要使用某个类时，JVM会确保这个类已经被加载、连接（验证、准备和解析）和初始化。 1.1 什么是类的加载&emsp;&emsp;类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在堆区创建一个java.lang.Class对象，用来封装类在方法区内的数据结构。类的加载的最终产品是位于堆区中的Class对象，Class对象封装了类在方法区内的数据结构，并且向Java程序员提供了访问方法区内的数据结构的接口。 &emsp;&emsp;类加载器并不需要等到某个类被“首次主动使用”时再加载它，JVM规范允许类加载器在预料某个类将要被使用时就预先加载它，如果在预先加载的过程中遇到了.class文件缺失或存在错误，类加载器必须在程序首次主动使用该类时才报告错误（LinkageError错误）如果这个类一直没有被程序主动使用，那么类加载器就不会报告错误。 二、类的加载过程 &emsp;&emsp;其中类加载的过程包括了加载、验证、准备、解析、初始化五个阶段。在这五个阶段中，加载、验证、准备和初始化这四个阶段发生的顺序是确定的，而解析阶段则不一定，它在某些情况下可以在初始化阶段之后开始，这是为了支持Java语言的运行时绑定（也成为动态绑定或晚期绑定）。另外注意这里的几个阶段是按顺序开始，而不是按顺序进行或完成，因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段。 2.1. 加载 &emsp;&emsp;加载主要是将.class文件（并不一定是.class。可以是ZIP包，网络中获取）中的二进制字节流读入到JVM中。 &emsp;&emsp;在加载阶段，JVM需要完成3件事： &emsp;&emsp;&emsp;1）通过类的全限定名获取该类的二进制字节流； &emsp;&emsp;&emsp;2）将字节流所代表的静态存储结构转化为方法区的运行时数据结构； &emsp;&emsp;&emsp;3）在内存中生成一个该类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。 &emsp;&emsp;加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中，而且在Java堆中也创建一个java.lang.Class类的对象（运行时的类型信息），这样便可以通过该对象访问方法区中的这些数据。 2.2 连接2.2.1. 验证&emsp;&emsp;验证是连接阶段的第一步，主要确保加载进来的字节流符合JVM规范。&emsp;&emsp;验证阶段会完成以下4个阶段的检验动作：&emsp;&emsp;&emsp;1）文件格式验证&emsp;&emsp;&emsp;2）元数据验证(是否符合Java语言规范)&emsp;&emsp;&emsp;3）字节码验证（确定程序语义合法，符合逻辑）&emsp;&emsp;&emsp;4）符号引用验证（确保下一步的解析能正常执行） 2.2.2. 准备&emsp;&emsp;准备阶段是正式为类变量分配内存并设置类变量的初始值阶段，即在方法区中分配这些变量所使用的内存空间。注意这里所说的初始值概念，比如一个类变量定义为： 1public static int v = 8080; &emsp;&emsp;实际上变量v在准备阶段过后的初始值为0而不是8080，将v赋值为8080的putstatic指令是程序被编译后，存放于类构造器方法之中。但是注意如果声明为： 1public static final int v = 8080; &emsp;&emsp;在编译阶段会为v生成ConstantValue属性，在准备阶段虚拟机会根据ConstantValue属性将v赋值为8080。 2.2.3. 解析&emsp;&emsp;解析阶段是指虚拟机将常量池中的符号引用替换为直接引用的过程。符号引用就是class文件中的： 123CONSTANT_Class_infoCONSTANT_Field_infoCONSTANT_Method_info 等类型的常量。下面我们解释一下符号引用和直接引用的概念：&emsp;&emsp;符号引用与虚拟机实现的布局无关，引用的目标并不一定要已经加载到内存中。各种虚拟机实现的内存布局可以各不相同，但是它们能接受的符号引用必须是一致的，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。&emsp;&emsp;直接引用可以是指向目标的指针，相对偏移量或是一个能间接定位到目标的句柄。如果有了直接引用，那引用的目标必定已经在内存中存在。 2.3 初始化&emsp;&emsp;初始化阶段是类加载过程的最后一步，主要是根据程序中的赋值语句主动为类变量赋值。 &emsp;&emsp;&emsp;注： &emsp;&emsp;&emsp;1）当有父类且父类为初始化的时候，先去初始化父类；&emsp;&emsp;&emsp;2）再进行子类初始化语句。 三、Jvm加载的过程图例 什么时候需要对类进行初始化？1）使用new该类实例化对象的时候；2）读取或设置类静态字段的时候（但被final修饰的字段，在编译器时就被放入常量池的静态字段除外static final）；3）调用类静态方法的时候；4）使用反射Class.forName(“xxxx”)对类进行反射调用的时候，该类需要初始化；5）初始化一个类的时候，有父类，先初始化父类（注：1. 接口除外，父接口在调用的时候才会被初始化；2.子类引用父类静态字段，只会引发父类初始化）；6）被标明为启动类的类（即包含main()方法的类）要初始化；7）当使用JDK1.7的动态语言支持时，如果一个java.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。 什么时候不会初始化？1）通过子类引用父类的静态字段，只会触发父类的初始化，而不会触发子类的初始化。2）定义对象数组，不会触发该类的初始化。3）常量在编译期间会存入调用类的常量池中，本质上并没有直接引用定义常量的类，不会触发定义常量所在的类。4）通过类名获取Class对象，不会触发类的初始化。5）通过Class.forName加载指定类时，如果指定参数initialize为false时，也不会触发类初始化，其实这个参数是告诉虚拟机，是否要对类进行初始化。6）通过ClassLoader默认的loadClass方法，也不会触发初始化动作。 四、类加载器类加载器负责对类的加载，加载类的方式有：1）从本地系统直接加载2）通过网络下载.class文件3）从zip，jar等归档文件中加载.class文件4）从专有数据库中提取.class文件5）将Java源文件动态编译为.class文件（服务器）","categories":[{"name":"基础知识","slug":"基础知识","permalink":"https://legatoplay.github.io/categories/基础知识/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://legatoplay.github.io/tags/JAVA/"},{"name":"JVM","slug":"JVM","permalink":"https://legatoplay.github.io/tags/JVM/"}]}]}